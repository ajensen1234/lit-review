#+AUTHOR: Andrew Jensen
#+TITLE: Joint Track Machine Learning
#+DATE: March 9, 2023
#+BIBLIOGRAPHY: ../src/myBib.bib
#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
#+OPTIONS:   H:2 num:t toc:f \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+HTML_LINK_UP:
#+HTML_LINK_HOME:

#+startup: beamer
#+LaTeX_CLASS: beamer

#+options: H:3
#+latex_class: beamer
#+LaTeX_CLASS_OPTIONS: [presentation, aspectratio=1610]
#+columns: %45ITEM %10 BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+beamer_theme: metropolis
#+latex_header: \usetheme[progressbar=foot]{metropolis}
#+latex_header: \usepackage[sorting=ynt]{biblatex}
#+latex_header_extra: \usepackage{caption}
#+latex_header_extra: \captionsetup[figure]{labelformat=empty}
#+latex_header_extra: \DeclareMathOperator*{\argmax}{\arg\!max}
#+latex_header_extra: \DeclareMathOperator*{\argmin}{\arg\!min}
#+latex_header_extra: \AtBeginSubsection{\begin{frame}\tableofcontents[currentsection,currentsubsection]\end{frame}}
#+beamer_color_theme:
#+beamer_font_theme:
#+beamer_inner_theme:
#+beamer_outer_theme:

* Introduction :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** Acknowledgments
:PROPERTIES:
:BEAMER_OPT: standout
:END:
I would like to thank the McJunkin Family Charitable Foundation for their generous grant that supports this work.

* Motivation :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** The Problem
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ By 2030, roughly 3.5 million Total Knee Arthroplasty (TKA) will be performed in the US [cite:@kurtzProjectionsPrimaryRevision2007].
+ 20% of patients receiving TKA are dissatisfied.
  + Instability, pain, unnatural [cite:@bakerRolePainFunction2007; @bournePatientSatisfactionTotal2010; @scottPredictingDissatisfactionFollowing2010].
+ No reliable method of clinically assessing and quantifying joint dynamics.
  + Human supervision
  + Time consuming
  + Specialized equipment
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_LaTeX: :width \textwidth
[[file:~/repo/lit-review/figures/raster/Physical_Examination_of_the_knee.jpg]]
*** Our Proposition
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
Orthopaedic surgeons and clinicians would readily adopt a **practical** and **inexpensive** technology that allows them to **measure** a patient's knee kinematics during **activities of daily living**.
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width 2in
[[file:~/repo/lit-review/figures/raster/dynamic-knee-prescription.png]]
*** Constraints
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:END:
+ It must fit within a **standard clinical workflow**
+ The technology must utilize equipment **commonly found in hospitals**
+ There must not be significant **human supervision** nor interaction to generate an examination report.
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width \textwidth
[[file:~/repo/lit-review/figures/raster/c-arm-fluoro-machine.jpg]]
* Background :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** Background - Projective Geometry
#+ATTR_latex: :width 0.8\textwidth
[[file:~/repo/lit-review/figures/raster/perspective-projection.png]]
*** Background - Model-Image Registration
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
If we know the projective parameters of the fluoroscopy machine, can we tinker with $T^{cam}_{implant}$ so that our virtual projection matches the fluoroscopic image?
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width 2.5in
#+CAPTION:From [cite:@mahfouzRobustMethodRegistration2003]
[[file:~/repo/lit-review/figures/raster/registered-tka.png]]
*** Background - Model-Image Registration
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
If we know the projective parameters of the fluoroscopy machine, can we tinker with $T^{cam}_{implant}$ so that our virtual projection matches the fluoroscopic image?
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width 2.5in
#+CAPTION:From [cite:@mahfouzRobustMethodRegistration2003]
file:~/repo/lit-review/figures/raster/mahfouz-perspective-projection.png
* Historical Methods :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** Historical Overview
Many different approaches have attempted to solve the model-image registration problem.
+ Pre-computed projections
+ Skin-mounted motion Capture
+ Biplane Imaging
+ Iterative Projections
+ Roentgen Stereophotogrammetry
*** Pre-Computed Projections
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Saving space and memory by pre-computing as much as possible.
+ Pre-computed distance maps [cite:@zuffiModelbasedMethodReconstruction1999; @lavalleeRecoveringPositionOrientation1995].
+ Pre-computed shape libraries [cite:@banksAccurateMeasurementThreedimensional1996]
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 1.75in
#+CAPTION: From [cite:@lavalleeRecoveringPositionOrientation1995]
[[file:~/repo/lit-review/figures/raster/lavallee-distance-maps.png]]
\vspace{-0.25in}
#+ATTR_LaTeX: :width 1.75in
#+CAPTION: From [cite:@banksAccurateMeasurementThreedimensional1996]
[[file:~/repo/lit-review/figures/raster/banks-nfd-library.png]]
*** Limitations of Pre-Computed Projections
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Requires an accurate contour from the input image in order to perform calculations.
  + Human supervision for isolated contour
  + Inaccuaracy with naive edge detection
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 1.75in
#+CAPTION: From [cite:@lavalleeRecoveringPositionOrientation1995]
[[file:~/repo/lit-review/figures/raster/lavallee-distance-maps.png]]
\vspace{-0.25in}
#+ATTR_LaTeX: :width 1.75in
#+CAPTION: From [cite:@banksAccurateMeasurementThreedimensional1996]
[[file:~/repo/lit-review/figures/raster/banks-nfd-library.png]]

*** Motion Capture (MoCap)
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Can measure motion of MoCap beads very accurately.
+ Skin-mounted [cite:@gaoInvestigationSoftTissue2008; @kuoInfluenceSoftTissue2011; @linEffectsSoftTissue2016].
+ Bone pins [cite:@lafortuneThreedimensionalKinematicsHuman1992].

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 2.5in
#+CAPTION: From [cite:@gaoInvestigationSoftTissue2008]
[[file:~/repo/lit-review/figures/raster/gao-skin-mocap.png]]
\vspace{-0.25in}
#+ATTR_LaTeX: :width 2.5in
#+CAPTION: From [cite:@lafortuneThreedimensionalKinematicsHuman1992]
[[file:~/repo/lit-review/figures/raster/lafortune-bone-mocap.png]]
*** Limitations of Motion Capture
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
Skin Mounted
+ Doesn't accurately describe underlying skeletal motion with clinical accuracy [cite:@gaoInvestigationSoftTissue2008; @kuoInfluenceSoftTissue2011; @linEffectsSoftTissue2016].
Bone Pins
+ Any volunteers?

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 2.5in
#+CAPTION: From [cite:@gaoInvestigationSoftTissue2008]
[[file:~/repo/lit-review/figures/raster/gao-skin-mocap.png]]
\vspace{-0.25in}
#+ATTR_LaTeX: :width 2.5in
#+CAPTION: From [cite:@lafortuneThreedimensionalKinematicsHuman1992]
[[file:~/repo/lit-review/figures/raster/lafortune-bone-mocap.png]]

*** Biplane Imaging
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_LaTeX: :width \textwidth
+ Utilizes multiple cameras to resolve 3D position and orientation[cite:@ivesterReconfigurableHighSpeedStereoRadiography2015; @burtonAutomaticTrackingHealthy2021].
  + Highly accurate.
  + Gold Standard.
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 1.75in
#+CAPTION: Both from [cite:@ivesterReconfigurableHighSpeedStereoRadiography2015]
[[file:~/repo/lit-review/figures/raster/ivester-stereo-fluoromachine.png]]
\vspace{-0.25in}
#+ATTR_LaTeX: :width 1.75in
#+CAPTION:
[[file:~/repo/lit-review/figures/raster/ivester-stereo-projection.png]]
*** Limitations of Biplane Imaging
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_LaTeX: :width \textwidth
+ Not many hospitals have biplane fluoroscopy setups.
+ Clinically impractical
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 1.75in
#+CAPTION: Both from [cite:@ivesterReconfigurableHighSpeedStereoRadiography2015]
[[file:~/repo/lit-review/figures/raster/ivester-stereo-fluoromachine.png]]
\vspace{-0.25in}
#+ATTR_LaTeX: :width 1.75in
#+CAPTION:
[[file:~/repo/lit-review/figures/raster/ivester-stereo-projection.png]]

*** Iterative Projections
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.54
:END:
+ Take advantage of modern computational graphics pipelines to quickly perform projection matching.
  + Image/Intensity similarity metrics [cite:@mahfouzRobustMethodRegistration2003]
  + Feature/Contour similarity metrics [cite:@floodAutomatedRegistration3D2018]
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 2in
#+CAPTION: From [cite:@mahfouzRobustMethodRegistration2003]
[[file:~/repo/lit-review/figures/raster/mahfouz-perspective-projection.png]]
#+ATTR_LaTeX: :width 2in
#+CAPTION: From [cite:@floodAutomatedRegistration3D2018]
[[file:~/repo/lit-review/figures/raster/flood-dilated-contour.png]]
*** Limitations of (historic) Iterative Projection Methods
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.54
:END:
+ Requires human supervision for:
  + Pose initialization
  + Escaping local minima
  + Implant detection
+ Chaotic and Noisy objective function
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 2in
#+CAPTION: From [cite:@mahfouzRobustMethodRegistration2003]
[[file:~/repo/lit-review/figures/raster/mahfouz-perspective-projection.png]]
#+ATTR_LaTeX: :width 2in
#+CAPTION: From [cite:@floodAutomatedRegistration3D2018]
[[file:~/repo/lit-review/figures/raster/flood-dilated-contour.png]]

*** Roentgen Stereophotogrammetry (RSA)
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Uses implanted tantalum beads for motion tracking [cite:@vroomanFastAccurateAutomated1998; @selvikRoentgenStereophotogrammetryMethod1989]
+ Extremely accurate [cite:@kapteinEvaluationThreePose2004; @saariKneeKinematicsMedial2005]
+ Gold standard Measurement [cite:@brobergValidationMachineLearning2023]

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width 3in
#+CAPTION: From [cite:@vroomanFastAccurateAutomated1998]
[[file:~/repo/lit-review/figures/raster/vrooman-mbrsa.png]]
*** Limitations of RSA
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Involves additional surgical procedures for inserting tantalum beads.
+ Human supervision
+ Bi-plane imaging
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width 3in
#+CAPTION: From [cite:@vroomanFastAccurateAutomated1998]
[[file:~/repo/lit-review/figures/raster/vrooman-mbrsa.png]]

* Aims
*** Aims
**** Aims 1/2 :B_block:BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_env: block
:END:
Joint Track Machine Learning and Overcoming Single-Plane Limitations
**** Aim 3/4 :B_block:BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_env: block
:END:
Pilot Trials and Standardized Kinematics Exam
**** Aim 5 :B_block:BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_env: block
:END:
Joint Track Auto Toolkit

** Aim 1 - Joint Track Machine Learning
*** Goal
Demonstrate the feasibility of a fully autonomous, model-image registration pipeline.
*** Method
+ Three-tiered approach
  + Convolutional Neural networks (CNN) for autonomous implant detection
  + Normalized Fourier Descriptor shape libraries
  + Robust contour-based global optimization scheme
#+ATTR_latex: :width \textwidth
[[file:~/repo/lit-review/figures/raster/pipeline-nocite.png]]
*** Autonomous Implant Detection Using Convolutional Neural Networks
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ 2 CNNs
  + Femoral and Tibial implants
+ High Resolution Network [cite:@wangDeepHighResolutionRepresentation2020]
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_latex: :width \columnwidth
[[file:~/repo/lit-review/figures/raster/jtml-segmentation.png]]
*** Neural Network Data
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ ~8000 images
   + 7 TKA kinematics studies
    + 71 subjects
    + 7 implant manufacturers
    + 36 distinct implants
    + Squat, lunge, kneel, stair ascent

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :height 3in
[[file:~/repo/lit-review/figures/raster/jtml-data.png]]
*** Neural Network Robustness
+ Additional augmentations introduced during training [cite:@buslaevAlbumentationsFastFlexible2020].
[[file:~/repo/lit-review/figures/raster/augmentations.png]]
*** Normalized Fourier Descriptor Shape Libraries
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.37
:END:
+ Pose initialization using segmentation output.
+ $\pm 30^{\circ}$ library span at $3^{\circ}$ increments.

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.7
:END:
#+ATTR_latex: :width 2in
[[file:~/repo/lit-review/figures/raster/banks-nfd-library.png]]
#+ATTR_latex: :width 3.25in
[[file:~/repo/lit-review/figures/raster/jtml-nfd.png]]
*** Pose Refinement Using Global Optimization
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Two main features
  + Objective function
  + Optimization routine
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_src latex

\begin{equation*}
    \argmin_{x}\{f(x) : x \in \Omega\}
\end{equation*}
#+end_src
*** Contour-based Objective Function
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ With accurate projection, contours provide a strong heuristic for orientation.
+ Overlapping pixels between CNN segmentation and projected implant.
  + $L_1$ norm has quick parallel computation.

#+begin_src latex
\begin{equation*}
  J = \sum_{i \in H}\sum_{j \in W}|I_{ij} - P_{ij}| = L_{1}(I,P)
\end{equation*}
#+end_src
+ Sensitive to minor perturbations
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
[[file:~/repo/lit-review/figures/raster/registered-tka.png]]
*** Improving Robustness
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
 + Dilation decreases sensitivity to perturbations.
 + Multi-stage optimization can reduce dilation back to original edges.
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width \textwidth
[[file:~/repo/lit-review/figures/raster/flood-dilated-contour.png]]
*** Optimization Routine
+ No analytic form of the objective function exists, it **must** be sampled at points of interest.
  + Black Box Optimization [cite:@audetDerivativeFreeBlackboxOptimization2017; @bajajBlackBoxOptimizationMethods2021]

*** Lipschitzian Optimization
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Robust, global, black-box optimization routine if Lipschitz constant ($K$) is known [cite:@shubertSequentialMethodSeeking1972].
+ Lipschitz constant bounds the rate of change of a function.
+ What if you don't know the Lipschitz constant?

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width 2in
[[file:~/repo/lit-review/figures/raster/shubert-step1.png]]
[[file:~/repo/lit-review/figures/raster/shubert-step2.png]]
[[file:~/repo/lit-review/figures/raster/shubert-step3.png]]

*** Lipschitzian Optimization without the Lipschitz Constant
#+ATTR_latex: :width 2.5in
[[file:~/repo/lit-review/figures/raster/jones-direct-title.png]]
+ Sample end-points instead of intersecting lines.
+ Potentially optimal regions based on value at center and total size.
  + Trisect potentially optimal regions and re-sample centers
#+ATTR_latex: :width 2.5in
[[file:~/repo/lit-review/figures/raster/direct-1D.png]]
*** Trisecting Region
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.4
:END:
#+begin_src latex
\begin{equation*}
  \begin{bmatrix}
    f(x=c_{1}) & d(c_{1})\\
    f(x=c_{2}) & d(c_{2})\\
    \vdots & \vdots \\
    f(x=c_{N}) & d(c_{N})
  \end{bmatrix}
\end{equation*}
Where

\begin{align*}
  f(x=c_{i}) &\equiv \text{Sampled function value} \\
  d(c_{i}) & \equiv \text{ Sub-domain size } \\
  & \text{ for } i \in [1,N]
\end{align*}
#+end_src
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width \textwidth
[[file:~/repo/lit-review/figures/raster/direct-1D-stage1.png]]
*** Another Iteration
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.4
:END:
#+begin_src latex
\begin{equation*}
  \begin{bmatrix}
    f(x=c_{1}) & d(c_{1})\\
    f(x=c_{2}) & d(c_{2})\\
    \vdots & \vdots \\
    f(x=c_{N}) & d(c_{N})
  \end{bmatrix}
\end{equation*}
Where

\begin{align*}
  f(x=c_{i}) &\equiv \text{Sampled function value} \\
  d(c_{i}) & \equiv \text{ Sub-domain size } \\
  & \text{ for } i \in [1,N]
\end{align*}
#+end_src
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width \textwidth
[[file:~/repo/lit-review/figures/raster/direct-1D-stage2.png]]

*** Determining Potentially Optimal Regions
+ Convex hull [cite:@grahamEfficientAlgorithDetermining1972; @jarvisIdentificationConvexHull1973; @chanOptimalOutputsensitiveConvex1996; @barberQuickhullAlgorithmConvex1996] of region size vs. center value

#+ATTR_latex: :width 0.6\textwidth
[[file:~/repo/lit-review/figures/raster/direct-convex-hull.png]]
*** DiRECT for Joint Track Machine Learning
+ Search region is along all 6 degrees of freedom.
  + Normalize to $[0,1]$.
+ Three stages, each with decreasing levels of dilation.
  + Iteration budget for each stage.
| Stage      | Budget [Iterations] | Search Range [mm,deg]                      | Dilation (pixels) |
|------------+---------------------+--------------------------------------------+-------------------|
| ``Tree''   | ~20,000             | $\pm 45$                                   |                 5 |
| ``Branch'' | ~20,000             | $\pm 25$                                   |                 3 |
| ``Leaf''   | ~10,000             | $\pm 100$ $(z_{trans})$ / $\pm 3$ $(else)$ |                 1 |
*** Testing Performance
Now that we have our refined poses, how well does out system perform?
#+ATTR_latex: :width \textwidth
[[file:~/repo/lit-review/figures/raster/pipeline-nocite.png]]
*** Validation
+ Independent research group using Model-Based RSA.
+ Determine the level of concordance between the two measurement systems
  + Bland-Altmann Plots
+ Achieved clinically acceptable accuracy [cite:@brobergValidationMachineLearning2023; @jensenJointTrackMachine2022].
+ Highly repeatable

#+ATTR_latex: :width 0.7\textwidth
file:~/repo/lit-review/figures/raster/broberg-bland-altmann.png
*** Awards
The work presented in this aim won the HAP Paul Award for Best Paper from the International Society for Technology in Arthroplasty's 2022 Annual Meeting.
#+ATTR_latex: :width 0.7\textwidth
[[file:~/repo/lit-review/figures/raster/ista-map-paul-talk.jpg]]
** Aim 2 - Overcoming Single-Plane Limitations
*** Goal
+ The goal of this aim is to validate and test methods that can overcome single-plane limitations for model-image registration.
  + Out-of-plane (OOP) Translation
  + Symmetry Traps

*** Translation
+ Depth perception is lost when using a single camera.
+ Utilize a virtual ``spring'' to constrain relative OOP translation between implant components.

#+begin_src latex
\begin{equation*}
  J = \alpha L_{1}(I,P) + \beta ML(Fem,Tib)
\end{equation*}

Where
\begin{equation*}
  ML \equiv \text{ Relative mediolateral translation }
\end{equation*}
#+end_src
*** Symmetry Traps
With a symmetric tibial implant, the contour is not always a perfect heuristic for true pose. Human operators typically utilize relative varus-valgus to determine correct pose.

Found ``ambiguous zone'' within $3^{\circ}$ of pure lateral pose with high propensity for symmetry traps [cite:@jensenJointTrackMachine2022].

#+ATTR_Latex: :width 0.7\textwidth
[[file:~/repo/lit-review/figs/jtml-paper/fig6-symtrap.png]]
*** Solving the Symmetric Pose
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
1. Create a vector from the camera origin to the implant origin (viewing ray).
2. Determine the axis ($\vec{m}$) and angle ($\theta$) of rotation between the viewing ray and the symmetric (mediolateral) axis.
3. Rotate the implant $-2\theta$ about the same axis.
4. The final location is the symmetric pose of the object.
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width 0.6\textwidth
[[file:~/repo/lit-review/figures/raster/sym-trap.png]]
*** Four Approaches
+ Virtual ligaments
+ Binary selection between two poses
+ Bland-Altmann Calibration Constant
+ Fully Connected Network

*** Virtual Ligaments
#+begin_src latex
\begin{equation*}
  J = \alpha L_{1}(I,P) + \beta ML(Fem,Tib) + \gamma VV(Fem,Tib)
\end{equation*}

Where

\begin{equation*}
  VV \equiv \text{  Relative Varus-Valgus rotation}
\end{equation*}
#+end_src
*** Binary Selection
1. Determine optimized pose using $L_1 + ML$
2. Calculate symmetric pose.
3. Pick pose with lower relative VV

This method can simplify the selection criteria (one fewer hyperparameter).
*** Bland-Altmann Calibration Constant
+ Utilizing Bland-Altmann plots from gold-standard kinematics, create a ``correction constant'' for relative varus/valgus (ad/abduction) angles.
+ Notice linear trend in BA plots.
#+ATTR_latex: :width 0.75\textwidth
[[file:~/repo/lit-review/figures/raster/broberg-bland-altmann.png]]

*** Fully Connected Network
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Encode symmetric pose calculation into FCN.
+ Feed femoral and tibial **pose** into network.
  + ``Keep'' or ``Switch''
+ Could incorporate categorical features as well
  + Weightbearing vs non-weightbearing
  + Activity (walking, stair, lunge, etc)

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width  2.2in
[[file:~/repo/lit-review/figures/raster/fcn.png]]

*** Timeline
+ All kinematics data has already been collected.
+ Completed Methods
  + Virtual Ligaments
+ In Progress
  + Binary Selection
+ Pending Methods
  + Bland-Altmann Calibration
  + Fully Connected Network

Journal paper will be ready for submission by June.

** Aim 3 - Pilot Human Study
*** Goal
No kinematics studies have exclusively utilized Joint Track Machine Learning; let's be the first.

What are we measuring?
+ Kinematics
+ Time to full examination report
  + Time/frame
  + Usage hiccups
  + Symmetry traps

*** Methods
+ 20-30 patients
+ ~Dozen activities with fluoroscopic machine
  + Weightbearing and Non-weightbearing
  + Static and Dynamic

IRB approval ~4 months out.

** Aim 4 - Standardized Kinematics Exam
*** Goal
Establish a ``standard kinematics exam'' by determining the most statistically and anatomically relevent fluoroscopic image(s) to capture during a clinical visit.
*** Motivation
+ We have standardized pain/outcome scores
  + KOOS, KSS, FJS, etc..
+ No standardized kinematics examination
  + Per-study differences
  + No reason to standardize

Autonomous kinematics measurements allow researchers to spend more time asking and answering questions rather than fiddling with annoying software.

*** Method
+ Use images and kinematics from Aim 3.
+ Utilize statistical methods to determine covariance and causal/corollary relationships.
  + Clustering
  + Transformers [cite:@carionEndtoEndObjectDetection2020; @vaswaniAttentionAllYou2017; @guoAttentionMechanismsComputer2021; @dosovitskiyImageWorth16x162021] (``translating'' movements into outcomes and other movements)
** Aim 5 - Joint Track Auto Toolkit
*** Joint Track Auto Toolkit (JTAT)
Create a freely available Python library that allows other researchers to utilize JTML's model-image registration framework. Extra emphasis will be placed on extensibility to allow other researchers to compose their own registration pipelines.
* Publications and Presentations :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** Presentations
:PROPERTIES:
:BEAMER_OPT: fragile, allowframebreaks, label=
:END:
#+begin_src latex
\begin{refsection}
  \input{nocites-pres}
  \printbibliography[title=Presentations]
\end{refsection}
#+end_src

*** Publications
:PROPERTIES:
:BEAMER_OPT: fragile, allowframebreaks, label=
:END:
#+begin_src latex
\begin{refsection}
  \input{nocites-pubs}
  \printbibliography[title=Publications]
\end{refsection}
#+end_src
* Timeline :B_ignoreheading:
:PROPERTIES:
:BEAMER_env: ignoreheading
:END:
*** Timeline
| Date(s)                    | Event                                                  |
|----------------------------+--------------------------------------------------------|
| 2015-2019                  | Mech. Eng. B.S, Magna Cum Laude, UF                    |
| April 2019 - April 2020    | Internship at Exactech                                 |
| April 2020                 | Started in Miller Lab                                  |
| August 2020                | Officially Started PhD at UF                           |
| November 2021              | Best Presentation Award at ISTA: Emerging Technologies |
| April 2022                 | Submitted JTML for HAP Paul Award                      |
| September 2022             | HAP Paul Award at ISTA 2022                            |
|----------------------------+--------------------------------------------------------|
| June 2023                  | Single-plane limitations paper submitted               |
| July 2023                  | Est. IRB Approval                                      |
| August 2023                | v1.0 JTAT                                              |
| December 2023 ~ May 2024   | Patient Data Fully Collected (Aims 3/4)                |
| August 2024                | Papers for Aims 3/4 Submitted                          |
| December 2024 - April 2025 | Est. Graduation                                        |
*** Thank you!
:PROPERTIES:
:BEAMER_OPT: standout
:END:
Thanks for listening!!
* References
*** References
:PROPERTIES:
:BEAMER_OPT: fragile, allowframebreaks, label=
:END:
#+begin_src latex
\AtNextBibliography{\tiny}
\printbibliography
#+end_src

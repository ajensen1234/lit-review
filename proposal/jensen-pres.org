#+AUTHOR: Andrew Jensen
#+TITLE: Joint Track Machine Learning
#+DATE: March 9, 2023
#+BIBLIOGRAPHY: ../src/myBib.bib
#+DESCRIPTION:
#+KEYWORDS:
#+LANGUAGE:  en
#+OPTIONS:   H:2 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+HTML_LINK_UP:
#+HTML_LINK_HOME:

#+startup: beamer
#+LaTeX_CLASS: beamer

#+options: H:3
#+latex_class: beamer
#+LaTeX_CLASS_OPTIONS: [presentation, aspectratio=1610]
#+columns: %45ITEM %10 BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+beamer_theme: metropolis
#+latex_header: \usetheme[progressbar=foot]{metropolis}
#+latex_header_extra: \usepackage{caption}
#+latex_header_extra: \captionsetup[figure]{labelformat=empty}
#+latex_header_extra: \AtBeginSubsection{\begin{frame}\tableofcontents[currentsection,currentsubsection]\end{frame}}
#+beamer_color_theme:
#+beamer_font_theme:
#+beamer_inner_theme:
#+beamer_outer_theme:

* Introduction
*** Acknowledgments
I would like to thank the McJunkin Family Charitable Foundation for their generous grant that supports this work.
* Motivation
*** The Problem
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ By 2030, roughly 3.5 million Total Knee Arthroplasty (TKA) will be performed in the US [cite:@kurtzProjectionsPrimaryRevision2007].
+ 20% of patients receiving TKA are dissatisfied.
  + Instability, pain, unnatural [cite:@bakerRolePainFunction2007; @bournePatientSatisfactionTotal2010; @scottPredictingDissatisfactionFollowing2010].
+ No reliable method of clinically assessing and quantifying joint dynamics.
  + Too much human supervision, too time consuming
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_LaTeX: :width \textwidth
[[file:~/repo/lit-review/figures/raster/Physical_Examination_of_the_knee.jpg]]
*** Our Proposition
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
Orthopaedic surgeons and clinicians would readily adopt a practical and inexpensive technology that allows them to measure a patient's knee kinematics during activities of daily living.
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width 2in
[[file:~/repo/lit-review/figures/raster/dynamic-knee-prescription.png]]
*** Constraints
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.45
:END:
+ It must fit within a standard clinical workflow
+ The technology must utilize equipment commonly found in hospitals
+ There must not be significant human supervision nor interaction to generate an examination report.
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.55
:END:
#+ATTR_LaTeX: :width \textwidth
[[file:~/repo/lit-review/figures/raster/c-arm-fluoro-machine.jpg]]
* Background
*** Rigid Body Transformations
**** Translation :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
#+begin_src latex
\begin{equation*}
  \begin{aligned}
  \begin{pmatrix}
    v_{x}' \\ v_{y}'
  \end{pmatrix} &=
  \begin{pmatrix}
    v_{x} \\ v_{y}
  \end{pmatrix} +
  \begin{pmatrix}
    t_{x} \\ t_{y}
  \end{pmatrix} \\
                & \rightarrow \\
    \begin{pmatrix}
      v_{x}' \\ v_{y}' \\ 1
    \end{pmatrix} &=
                    \begin{pmatrix}
                      1 & 0 & t_{x} \\ 0 & 1 & t_{y} \\ 0 & 0 & 1
                    \end{pmatrix}
                                                                \begin{pmatrix}
                                                                  v_{x} \\ v_{y} \\  1
                                                                \end{pmatrix}
\end{aligned}
\end{equation*}
#+end_src
*** Rigid Body Transformations
**** Rotations :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
#+begin_src latex
\begin{equation*}
  \begin{aligned}
    R_{x} & =
            \begin{pmatrix}
              1 & 0 & 0 \\
              0 & c_{x} & -s_{x}\\
              0 & s_{x} & c_{x}
            \end{pmatrix} \\
    R_{y} &=
            \begin{pmatrix}
              s_{y} & 0 & c_{y}\\
              0 & 1 & 0 \\
              c_{y} & 0 & -s_{y}
            \end{pmatrix} \\
    R_{z} &=
            \begin{pmatrix}
              c_{z} & -s_{z} & 0 \\
              s_{z} & c_{z} & 0 \\
              0 & 0 & 1
            \end{pmatrix}
  \end{aligned}
\end{equation*}
#+end_src
*** Rigid Body Transformations
**** Homogeneous Transformation Matrices :B_block:
:PROPERTIES:
:BEAMER_env: block
:END:
#+begin_src latex
\begin{equation*}
  \begin{aligned}
  \tilde{\vec{v'}} &=
  \begin{pmatrix}
    & \mathbf{R}_{3 \times 3} & & \vec{t}_{3 \times 1} \\
    0 & 0 & 0 & 1
  \end{pmatrix}\tilde{\vec{v}} \\
    &= T^{A}_{B} \tilde{\vec{v}}
  \end{aligned}
\end{equation*}
#+end_src
Now we have a notation that allows us to describe arbitrary movement between reference frames.
*** Projective Geometry
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+begin_src latex
\begin{equation*}
  \begin{pmatrix}
    x_{s} \\ y_{s} \\ z_{s} \\ 1
  \end{pmatrix}_{i} = T^{cam}_{scene} \mathbf{\tilde{p}^{obj}_{i}}
\end{equation*}
#+end_src
#+begin_src latex
\begin{equation*}
  \begin{pmatrix}
    \tilde{x}_{img} \\ \tilde{y}_{img} \\ \tilde{z}
  \end{pmatrix} =
  \begin{pmatrix}
    f& 0 & 0 \\ 0 & f & 0 \\ 0 & 0 & 1
  \end{pmatrix} \vec{x}_{s}
\end{equation*}

Where
\begin{equation*}
  \begin{aligned}
    x_{img} &= \frac{\tilde{x_{img}}}{\tilde{z}} = \frac{f}{z_{s}}x_{s} \\
    y_{img} &= \frac{\tilde{y_{img}}}{\tilde{z}} = \frac{f}{z_{s}}y_{s}
  \end{aligned}
\end{equation*}

{\tiny Note: We are still in the camera's reference frame}
#+end_src
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
[[file:~/repo/lit-review/figures/raster/perspective-projection.png]]
*** Pixel Coordinates
Convert camera coordinates into image coordinates.
#+begin_src latex
\begin{equation*}
  \begin{aligned}
    p_{x} = k_{x}x_{img} + c_{x} \\
    p_{y} = k_{y}y_{img} + c_{y}
  \end{aligned}
\end{equation*}
Where
\begin{equation*}
  \begin{aligned}
    k &\equiv \text{ Pixel Spacing }\\
    c &\equiv \text{ Image Focal Point }
  \end{aligned}
\end{equation*}
#+end_src
*** Model-Image Registration
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
If we know the projective parameters of the fluoroscopy machine, can we tinker with $T^{cam}_{implant}$ so that our virtual projection matches the fluoroscopic image?
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width 2.5in
#+CAPTION:From [cite:@mahfouzRobustMethodRegistration2003]
file:~/repo/lit-review/figures/raster/mahfouz-perspective-projection.png
* Historical Methods
*** Overview
Many different approaches have attempted to solve the model-image registration problem.
+ Pre-computed projections
+ Skin-mounted motion Capture
+ Biplane Imaging
+ Iterative Projections
+ Model-based Roentgen Stereophotogrammetry
*** Pre-Computed Projections
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Saving space and memory by pre-computing as much as possible.
+ Pre-computed distance maps [cite:@zuffiModelbasedMethodReconstruction1999; @lavalleeRecoveringPositionOrientation1995].
+ Pre-computed shape libraries [cite:@banksAccurateMeasurementThreedimensional1996]
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 1.75in
#+CAPTION: From [cite:@lavalleeRecoveringPositionOrientation1995]
[[file:~/repo/lit-review/figures/raster/lavallee-distance-maps.png]]
\vspace{-0.25in}
#+ATTR_LaTeX: :width 1.75in
#+CAPTION: From [cite:@banksAccurateMeasurementThreedimensional1996]
[[file:~/repo/lit-review/figures/raster/banks-nfd-library.png]]
*** Limitations of Pre-Computed Projections
+ Requires an accurate contour from the input image in order to perform calculations.
  + Human supervision vs. inaccuracy.

*** Motion Capture (MoCap)
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Can measure motion of MoCap beads very accurately.
+ Skin-mounted [cite:@gaoInvestigationSoftTissue2008; @kuoInfluenceSoftTissue2011; @linEffectsSoftTissue2016].
+ Bone pins [cite:@lafortuneThreedimensionalKinematicsHuman1992] (any volunteers?).

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 2.5in
#+CAPTION: From [cite:@gaoInvestigationSoftTissue2008]
[[file:~/repo/lit-review/figures/raster/gao-skin-mocap.png]]
\vspace{-0.25in}
#+ATTR_LaTeX: :width 2.5in
#+CAPTION: From [cite:@lafortuneThreedimensionalKinematicsHuman1992]
[[file:~/repo/lit-review/figures/raster/lafortune-bone-mocap.png]]
*** Limitations of Motion Capture
Skin Mounted
+ Doesn't accurately describe underlying skeletal motion with clinical accuracy [cite:@gaoInvestigationSoftTissue2008; @kuoInfluenceSoftTissue2011; @linEffectsSoftTissue2016].
Bone Pins
+ Bone Pins
+ Need I say more?
*** Biplane Imaging
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_LaTeX: :width \textwidth
+ Utilizes multiple cameras to resolve 3D position and orientation[cite:@ivesterReconfigurableHighSpeedStereoRadiography2015; @burtonAutomaticTrackingHealthy2021].
  + Highly accurate.
  + Gold Standard.
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 1.75in
#+CAPTION: Both from [cite:@ivesterReconfigurableHighSpeedStereoRadiography2015]
[[file:~/repo/lit-review/figures/raster/ivester-stereo-fluoromachine.png]]
\vspace{-0.25in}
#+ATTR_LaTeX: :width 1.75in
#+CAPTION:
[[file:~/repo/lit-review/figures/raster/ivester-stereo-projection.png]]
*** Limitations of Biplane Imaging
+ Not many hospitals have biplane fluoroscopy setups.
+ Clinically impractical

*** Iterative Projections
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.54
:END:
+ Take advantage of modern computational graphics pipelines to quickly perform projection matching.
  + Image/Intensity similarity metrics [cite:@mahfouzRobustMethodRegistration2003]
  + Feature/Contour similarity metrics [cite:@floodAutomatedRegistration3D2018]
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_LaTeX: :width 2in
#+CAPTION: From [cite:@mahfouzRobustMethodRegistration2003]
[[file:~/repo/lit-review/figures/raster/mahfouz-perspective-projection.png]]
#+ATTR_LaTeX: :width 2in
#+CAPTION: From [cite:@floodAutomatedRegistration3D2018]
[[file:~/repo/lit-review/figures/raster/flood-dilated-contour.png]]
*** Limitations of (historic) Iterative Projection Methods
+ Requires human supervision for:
  + Pose initialization
  + Escaping local minima
  + Implant detection
+ Chaotic and Noisy objective function

*** Model-based Roentgen Stereophotogrammetry (MBRSA)
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Uses implanted tantalum beads for motion tracking [cite:@vroomanFastAccurateAutomated1998; @selvikRoentgenStereophotogrammetryMethod1989]
+ Extremely accurate [cite:@kapteinEvaluationThreePose2004; @saariKneeKinematicsMedial2005]
+ Gold standard Measurement [cite:@brobergValidationMachineLearning2023]

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width 3in
#+CAPTION: From [cite:@vroomanFastAccurateAutomated1998]
[[file:~/repo/lit-review/figures/raster/vrooman-mbrsa.png]]
*** Limitations of MBRSA
+ Involves additional surgical procedures for inserting tantalum beads
+ Human supervision
+ Typically requires bi-plane imaging.

* Aims
*** Aims
**** Aims 1/2 :B_block:BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_env: block
:END:
Joint Track Machine Learning and Overcoming Single-Plane Limitations
**** Aim 3/4 :B_block:BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_env: block
:END:
Pilot Trials and Standardized Kinematics Exam
**** Aim 5 :B_block:BMCOL:
:PROPERTIES:
:BEAMER_col: 0.3
:BEAMER_env: block
:END:
Joint Track Auto Toolkit

** Aim 1 - Joint Track Machine Learning
*** Goal
Demonstrate the feasibility of a fully autonomous, model-image registration pipeline.
*** Method
+ Three-tiered approach
  + Convolutional Neural networks (CNN) for autonomous implant detection
  + Normalized Fourier Descriptor shape libraries
  + Robust contour-based global optimization scheme
[[file:~/repo/lit-review/figures/raster/pipeline-nocite.png]]
*** Autonomous Implant Detection Using Convolutional Neural Networks
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ 2 CNNs
  + Femoral and Tibial implants
+ High Resolution Network [cite:@wangDeepHighResolutionRepresentation2020]
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
#+ATTR_latex: :width \columnwidth
[[file:~/repo/lit-review/figures/raster/jtml-segmentation.png]]
*** Neural Network Data
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ ~8000 images
   + 7 TKA kinematics studies
    + 71 subjects
    + 7 implant manufacturers
    + 36 distinct implants
    + Squat, lunge, kneel, stair ascent

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :height 3in
[[file:~/repo/lit-review/figures/raster/jtml-data.png]]
*** Neural Network Robustness
+ Additional augmentations introduced during training [cite:@buslaevAlbumentationsFastFlexible2020].
[[file:~/repo/lit-review/figures/raster/augmentations.png]]
*** Normalized Fourier Descriptor Shape Libraries
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.37
:END:
+ Pose initialization using segmentation output.
+ $\pm 30^{\circ}$ library span at $3^{\circ}$ increments.

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.7
:END:
#+ATTR_latex: :width 2in
[[file:~/repo/lit-review/figures/raster/banks-nfd-library.png]]
#+ATTR_latex: :width 3.25in
[[file:~/repo/lit-review/figures/raster/jtml-nfd.png]]
*** Pose Refinement Using Global Optimization
+ Two main features
  + Objective function
  + Optimization routine
*** Contour-based Objective Function
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ With accurate projection, contours provide a strong heuristic for orientation.
+ Overlapping pixels between CNN segmentation and projected implant.
  + $L_1$ norm has quick parallel computation.

#+begin_src latex
\begin{equation*}
  J = \sum_{i \in H}\sum_{j \in W}|I_{ij} - P_{ij}| = L_{1}(I,P)
\end{equation*}
#+end_src
+ Sensitive to minor perturbations
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
[[file:~/repo/lit-review/figures/raster/jtml-registered-implant.png]]
*** Improving Robustness
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
 + Dilation decreases sensitivity to perturbations.
 + Multi-stage optimization can reduce dilation back to original edges.
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width \textwidth
[[file:~/repo/lit-review/figures/raster/flood-dilated-contour.png]]
*** Optimization Routine
+ No analytic form of the objective function exists, it **must** be sampled at points of interest.
  + Black Box Optimization [cite:@audetDerivativeFreeBlackboxOptimization2017; @bajajBlackBoxOptimizationMethods2021]

*** Lipschitzian Optimization
**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.5
:END:
+ Robust, global, black-box optimization routine if Lipschitz constant ($K$) is known [cite:@shubertSequentialMethodSeeking1972].
+ Lipschitz constant bounds the rate of change of a function.
+ What if you don't know the Lipschitz constant?

**** :BMCOL:
:PROPERTIES:
:BEAMER_col: 0.6
:END:
#+ATTR_latex: :width 2in
[[file:~/repo/lit-review/figures/raster/shubert-step1.png]]
[[file:~/repo/lit-review/figures/raster/shubert-step2.png]]
[[file:~/repo/lit-review/figures/raster/shubert-step3.png]]

*** Lipschitzian Optimization without the Lipschitz Constant
#+ATTR_latex: :width 2.5in
[[file:~/repo/lit-review/figures/raster/jones-direct-title.png]]
+ Sample end-points instead of intersecting lines.
+ Potentially optimal regions based on value at center and total size.
  + Trisect potentially optimal regions and re-sample centers
#+ATTR_latex: :width 2.5in
[[file:~/repo/lit-review/figures/raster/direct-1D.png]]
*** Determining Potentially Optimal Regions
+ Convex hull of region size vs. center value
#+ATTR_latex: :width 0.6\textwidth
[[file:~/repo/lit-review/figures/raster/direct-convex-hull.png]]
*** DiRECT for Joint Track Machine Learning
+ Search region is along all 6 degrees of freedom.
  + Normalize to $[0,1]$.
+ Three stages, each with decreasing levels of dilation.
  + Iteration budget for each stage.
| Stage      | Budget [Iterations] | Search Range [mm,deg]                      | Dilation (pixels) |
|------------+---------------------+--------------------------------------------+-------------------|
| ``Tree''   | ~20,000             | $\pm 45$                                   |                 5 |
| ``Branch'' | ~20,000             | $\pm 25$                                   |                 3 |
| ``Leaf''   | ~10,000             | $\pm 100$ $(z_{trans})$ / $\pm 3$ $(else)$ |                 1 |

*** Validation
+ Achieved clinically acceptable accuracy [cite:@brobergValidationMachineLearning2023; @jensenJointTrackMachine2022].
#+ATTR_latex: :width 0.85\textwidth
file:~/repo/lit-review/figures/raster/broberg-bland-altmann.png
*** Awards
The work presented in this aim won the HAP Paul Award for Best Paper from the International Society for Technology in Arthroplasty's 2022 Annual Meeting.

** Aim 2 - Overcoming Single-Plane Limitations
*** Goal
+ The goal of this aim is to validate and test methods that can overcome single-plane limitations for model-image registration.
  + Out-of-plane (OOP) Translation
  + Symmetry Traps

*** Translation
+ Depth perception is lost when using a single camera.
+ Utilize a virtual ``spring'' to constrain relative OOP translation between implant components.

#+begin_src latex
\begin{equation*}
  J = \alpha L_{1}(I,P) + \beta ML(Fem,Tib)
\end{equation*}

Where
\begin{equation*}
  ML \equiv \text{ Relative mediolateral translation }
\end{equation*}
#+end_src
*** Symmetry Traps
With a symmetric tibial implant, the contour is not always a perfect heuristic for true pose. Human operators typically utilize relative varus-valgus to determine correct pose.

Found ``ambiguous zone'' within $3^{\circ}$ of pure lateral pose with high propensity for symmetry traps [cite:@jensenJointTrackMachine2022].

#+ATTR_Latex: :width 0.7\textwidth
[[file:~/repo/lit-review/figs/jtml-paper/fig6-symtrap.png]]
*** Solving the Symmetric Pose
1. Create a vector from the camera origin to the implant origin (viewing ray).
2. Determine the axis ($\vec{m}$) and angle ($\theta$) of rotation between the viewing ray and the symmetric (mediolateral) axis.
3. Rotate the implant $-2\theta$ about the same axis.
4. The final location is the symmetric pose of the object.

*** Five Approaches
+ Virtual ligaments
+ Binary selection between two poses
+ Bland-Altmann Calibration Constant
+ Random Forest
+ Fully Connected Network

*** Virtual Ligaments
#+begin_src latex
\begin{equation*}
  J = \alpha L_{1}(I,P) + \beta ML(Fem,Tib) + \gamma VV(Fem,Tib)
\end{equation*}

Where

\begin{equation*}
  VV \equiv \text{  Relative Varus-Valgus rotation}
\end{equation*}
#+end_src
*** Binary Selection
1. Determine optimized pose using $L_1 + ML$
2. Calculate symmetric pose.
3. Pick pose with lower relative VV

This method can simplify the selection criteria (one fewer hyperparameter).
*** Bland-Altmann Calibration Constant
+ Utilizing Bland-Altmann plots from gold-standard kinematics, create a ``correction constant'' for relative varus/valgus (ad/abduction) angles.
+ Notice linear trend in BA plots.
#+ATTR_latex: :width 0.75\textwidth
[[file:~/repo/lit-review/figures/raster/broberg-bland-altmann.png]]


*** Random Forest
Train a random forest with femoral implant pose and both symmetric tibial poses.
[[file:~/repo/lit-review/figures/raster/random-forest.png]]
*** Fully Connected Network
+ Encode symmetric pose calculation into FCN.
+ Feed femoral and tibial pose into network.
  + ``Keep'' or ``Switch''
#+ATTR_latex: :width  2.2in
[[file:~/repo/lit-review/figures/raster/fcn.png]]

** Aim 3 - Pilot Human Study
*** Goal
No kinematics studies have exclusively utilized Joint Track Machine Learning; let's be the first.

What are we measuring?
+ Kinematics
+ Time to full examination report
  + Time/frame
  + Usage hiccups
  + Symmetry traps


** Aim 4 - Standardized Kinematics Exam
*** Goal
Anatomically and statistically determine the highest yield movements to measure to establish a ``standard kinematics exam''.
*** Motivation
+ We have standardized pain/outcome scores
  + KOOS, KSS, FJS, etc..
+ No standardized kinematics examination
  + Per-study differences
  + No reason to standardize

Autonomous kinematics measurements allow researchers to spend more time asking questions, rather than fiddling with annoying software.

*** Method
+ Consult with clinicians and researchers to determine wide ranging motions and static poses.
+ Utilize statistical methods to determine covariance and causal/corollary relationships.
  + Clustering
  + Transformers [cite:@carionEndtoEndObjectDetection2020; @vaswaniAttentionAllYou2017; @guoAttentionMechanismsComputer2021; @dosovitskiyImageWorth16x162021] (``translating'' movements into outcomes and other movements)
** Aim 5 - Joint Track Auto Toolkit
*** Goal
Create a freely available Python library that allows other researchers to utilize JTML's model-image registration framework. Extra emphasis will be placed on extensibility to allow other researchers to compose their own registration pipelines.
* References
*** References
:PROPERTIES:
:BEAMER_OPT: fragile, allowframebreaks, label=
:END:
#+begin_src latex
\AtNextBibliography{\tiny}
\printbibliography
#+end_src

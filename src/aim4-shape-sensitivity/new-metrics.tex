\subsection{Introduction}
Due to the relatively poor performance of the standard optimization algorithm (DIRECT \cite{jonesLipschitzianOptimizationLipschitz1993,floodAutomatedRegistration3D2018}) and the cost function ($L_{1}$-distance or Hamming Distance \cite{floodAutomatedRegistration3D2018}), the first step was to determine whether a more robust representation of image similarity might offer a stronger performance (\cref{sec:image-similarity}).
There are a few approaches that were used to determine a more robust image similarity description that might make it easier to find a global minima for this model-image registration problem.

Firstly, we considered enhancing the convexity of the problem.
In the current formulation, the cost is at its maximum error ($\sum I + P$) when there is no overlap between the projection and the CNN, regardless of whether the projection is off by 5 pixels or 500 pixels.
This issue necessitates a more nuanced error gradient.

Secondly, we delved into the psychology of shape.
Since manual registration serves as the benchmark for ground-truth kinematics, understanding human perception of shape differences and overlaps is crucial.

Lastly, consultations with surgeons and engineers experienced in manual kinematics measurements were sought. Their insights into effective procedures and features for accurate registration are invaluable for refining our approach.

There were some constraints when exploring the addition of new cost parameters for Joint Track Machine Learning.
Primarily, no new cost functions could conflict with the established Hamming Distance, meaning all additional metrics must reach their minimum concurrently with the Hamming distance.
Additionally, the algorithm needed to support parallel processing in CUDA without significantly increasing the computational load per image.
Maintaining the current efficiency, where only one error kernel is required per iteration, was crucial to preserve application performance.

\subsection{Improving Error Gradient}
In order to improve the gradient, some notion of ``closeness'' and ``farness'' needs to be established in the image plane, beyond just ``hits'' and ``misses'' that are counted during the Hamming distance.

The general class of functions that satisfy this propery, while also offering consistent minima with the Hamming distance are called \textit{surface distances} \cite{reinkeCommonLimitationsImage2023,reinkeUnderstandingMetricrelatedPitfalls2023}.
A surface distance is exactly the mathematical formulation that captures this notion of ``closeness'' or ``farness'' from one contour to another contour in an image plane.
A sub-distinction of surface distances are \emph{symmetric surface distances}, in which $d(a,b) = d(b,a)$, but this need not be the case for a useful metric.
There are four main recommended metrics for evaluating the surface distance.

The first is the Normalized Surface Distance or Normalized Surface Dice (\Cref{fig:surfDICE}) \cite{nikolovClinicallyApplicableSegmentation2021} .
Unfortunately, surface DICE runs into the same issue as Hamming distance where it is maximized at points of no overlap, but does not make true distinctions between closer and farther estimations.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{~/figures/raster/NSD.png}
  \caption{A graphical representation of the Normalized Surface Distance from \cite{reinkeUnderstandingMetricrelatedPitfalls2023,reinkeCommonLimitationsImage2023}}.
  \label{fig:surfDICE}
\end{figure}

The second is the Mean Average Surface Distance or Mean Surface Distance (\Cref{fig:MASD}) \cite{benesPerformanceEvaluationImage2015}.
This measures the \emph{mean} of the \emph{averages} over all shortest distances from all points on one boundary to any point on another boundary \cite{reinkeCommonLimitationsImage2023,reinkeUnderstandingMetricrelatedPitfalls2023}.
A major pitfall of this method is that calculating the average distance to the estimation would require spawning one sub-kernel per sampled pixel on the target and estimated contour, which would increase the number of computations by multiple orders of magnitude.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{~/figures/raster/MASD.png}
  \caption{A graphical representation of the Mean Average Surface Distance from \cite{reinkeCommonLimitationsImage2023,reinkeUnderstandingMetricrelatedPitfalls2023}}.
  \label{fig:MASD}
\end{figure}

The third is the Average Symmetric Surface Distance (\Cref{fig:ASSD}) \cite{yeghiazaryanFamilyBoundaryOverlap2018}.
This is a symmetric variation of the mean average surface distance, which does not take the mean of the average shortest distances, but rather just the average distance from both contours to the other contour.
This encounters the same issue as the Mean Average Surface Distance, requiring sub-kernels to calculate distances for each sampled point, drastically increasing the required number of computations per iteration.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{~/figures/raster/ASSD.png}
  \caption{A graphical representation of the Average Symmetric Surface Distance from \cite{reinkeUnderstandingMetricrelatedPitfalls2023,reinkeCommonLimitationsImage2023}}.
  \label{fig:ASSD}
\end{figure}

The last is the Hausdorff Distance (\Cref{fig:HD}) \cite{huttenlocherMultiresolutionTechniqueComparing1993,felzenszwalbDistanceTransformsSampled2012,huttenlocherComparingImagesUsing1993}.
The Hausdorff distance is the maximum distance from a point on one boundary to the nearest point on another boundary. Typically the Hausdorf distance for an entire countour is taken as the average of the Hausdorff distances for a series of sampled points on the target contour.
Like the previous two, the Hamming distance requires sub-kernels for every sampled point, and so it is not feasible.


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{~/figures/raster/HausdorfDistance.png}
  \caption{A graphical representation of the Hausdorff Distance, taken from \cite{reinkeCommonLimitationsImage2023,reinkeUnderstandingMetricrelatedPitfalls2023}}.
  \label{fig:HD}
\end{figure}

At this point, all recommended distance metrics do not satisfy our criteria for a feasible cost function that introduces an error gradient.
Based on the pitfalls of each of the above, the ability to pre-compute as many values as possible in order to reduce the algorithmic load during optimization seems ideal.
In previous work, 3D distance maps were pre-computed to perform medical model-image registration \cite{lavalleeRecoveringPositionOrientation1995,zuffiModelbasedMethodReconstruction1999}.
And so, a cost function was devised that can utilized pre-computed distance maps to introduce an error gradient, without needing to spawn multiple kernels during each iteration of optimization.

\subsection{Modified Mean Distance Cost Function}
First, rather than looking at an average distance of all points on the target (a process which spawns multiple sub-kernels), we introduce a distance map which encodes the distance to the \emph{closest point} on the target contour.

With an arbitrary image point defined as $p_{xy}$, and the target contour defined as $T$, we can express this distance map as a grid, $\displaystyle DM_{xy}(T) = \min_{t\in T}d(p_{xy},t)$, where $d(p_{xy},t)$ is any distance function that you want to use. In our case, we use the $L_{1}$-distance for efficient computation.

And then, one can express a notion of distance between the projected contour and the target contour by taking the average of the element-wise multiplication between the projection and the pre-calculated distance map (\cref{eq:DMCF}).
This has the major benefit of only needing a single kernel for each iteration (we are only iterating once per projection and performing a multiplication and atomic addition in memory) as well as sharing a minimum with the Hamming distance.
We can see this by noticing that $DM_{x,y}=0$ for points on the target contour, and so, if $Proj_{x,y}$ were perfectly aligned with this contour, our summation would simply be adding zeros.

\begin{equation}
  \label{eq:DMCF}
  J = \dfrac{ \sum_{(x,y) \in \text{Image}} Proj_{x,y}DM_{x,y} }{\sum_{(x,y)\in \text{Image}}Proj_{x,y}}
\end{equation}

Unfortunately, the results of this endeavor do not improve the overall performance of the DIRECT algorithm in finding a global minima for rTSA implants.
The performance is very similar to the poor performance noticed during the Hamming distance.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Jensen-Lit-Review"
%%% End:

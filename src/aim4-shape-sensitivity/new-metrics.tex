Given the relatively poor performance of the standard optimization algorithm (DIRECT \cite{jonesLipschitzianOptimizationLipschitz1993,floodAutomatedRegistration3D2018}) and the cost function ($L_{1}$-distance or Hamming Distance \cite{floodAutomatedRegistration3D2018}), this study initially investigated the potential for a more robust image similarity representation to enhance performance (\cref{sec:image-similarity}).
The identification of global minima in this model-image registration challenge was facilitated by exploring several approaches to enhance image similarity representation.

The first approach involved attempts to enhance the convexity of the problem.
With the existing formulation, the cost was observed to reach maximum error ($\sum I + P$) when there was no overlap between the projection and the CNN, regardless of the projection's deviation, whether it be 5 or 500 pixels.
This highlighted the need for a more nuanced error gradient.

Secondly, an exploration of the perceptual psychology of shape was undertaken \cite{attneaveInformationalAspectsVisual1954,attneaveQuantitativeStudyShape1956}.
Given that manual registration is considered the benchmark for ground-truth kinematics, an understanding of human perception of shape differences and overlaps was deemed crucial.
Consultations with surgeons and engineers were conducted, providing invaluable insights into refining the registration approach, with an emphasis on identifying effective procedures and features.

Exploring the addition of new cost parameters for JointTrack Machine Learning faced certain constraints.
The introduction of new cost functions was required to be non-conflicting with the Hamming Distance, necessitating their concurrent minimization with the Hamming Distance for all additional metrics.
Furthermore, the algorithm was required to support parallel processing in CUDA without significantly increasing the computational burden per image.
Lastly, maintaining the existing efficiency, characterized by the necessity for only one kernel per iteration to preserve application performance, was considered crucial.




\subsection{Improving Error Gradient}
For gradient enhancement, it is essential to establish notions of \emph{closeness} and \emph{farness} in the image plane, which transcends the basic \emph{hits} and \emph{misses} of the Hamming distance calculation.
Functions that satisfy this property and provide consistent minima with the Hamming distance are defined as \textit{surface distances} \cite{reinkeCommonLimitationsImage2023,reinkeUnderstandingMetricrelatedPitfalls2023}.
A surface distance represents the mathematical formulation which captures the concept of closeness or farness between contours in an image plane.
Within surface distances, a notable subcategory is \emph{symmetric surface distances}, characterized by the equality $d(a,b) = d(b,a)$; however, this symmetry is not a prerequisite for a metric to be useful.
Four primary metrics are widely recommended for the evaluation of surface distance \cite{reinkeUnderstandingMetricrelatedPitfalls2023,reinkeCommonLimitationsImage2023}.

The first is the Normalized Surface Distance or Normalized Surface Dice (\Cref{fig:surfDICE}) \cite{nikolovClinicallyApplicableSegmentation2021} .
However, surface DICE encounters a similar limitation as the Hamming distance, being maximized at points of no overlap, without discerning between closer and farther estimations.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{~/figures/raster/NSD.png}
  \caption{A graphical representation of the Normalized Surface Distance from \cite{reinkeUnderstandingMetricrelatedPitfalls2023,reinkeCommonLimitationsImage2023}.}
  \label{fig:surfDICE}
\end{figure}

The second is the Mean Average Surface Distance or Mean Surface Distance (\Cref{fig:MASD}) \cite{benesPerformanceEvaluationImage2015}.
This metric calculates the average of the mean shortest distances from every point on one boundary to any point on the other boundary \cite{reinkeCommonLimitationsImage2023,reinkeUnderstandingMetricrelatedPitfalls2023}.
A significant drawback of this method lies in its requirement to spawn a sub-kernel for each sampled pixel on the target and estimated contour, substantially increasing the computational load.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{~/figures/raster/MASD.png}
  \caption{A graphical representation of the Mean Average Surface Distance from \cite{reinkeCommonLimitationsImage2023,reinkeUnderstandingMetricrelatedPitfalls2023}.}
  \label{fig:MASD}
\end{figure}

The third is the Average Symmetric Surface Distance (\Cref{fig:ASSD}) \cite{yeghiazaryanFamilyBoundaryOverlap2018}.
This metric represents a symmetric variation of the mean average surface distance, calculating the average distance from each contour to the other, rather than the mean of the average shortest distances.
Similar to the Mean Average Surface Distance, this metric also necessitates sub-kernels for each sampled point, significantly increasing the computational requirements per iteration.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{~/figures/raster/ASSD.png}
  \caption{A graphical representation of the Average Symmetric Surface Distance from \cite{reinkeUnderstandingMetricrelatedPitfalls2023,reinkeCommonLimitationsImage2023}.}
  \label{fig:ASSD}
\end{figure}

The last is the Hausdorff Distance (\Cref{fig:HD}) \cite{huttenlocherMultiresolutionTechniqueComparing1993,felzenszwalbDistanceTransformsSampled2012,huttenlocherComparingImagesUsing1993}.
The Hausdorff distance is the maximum distance from a point on one boundary to the nearest point on another boundary. Typically the Hausdorf distance for an entire countour is taken as the average of the Hausdorff distances for a series of sampled points on the target contour.
Like the previous two, the Hamming distance requires sub-kernels for every sampled point, and so it is not feasible.


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{~/figures/raster/HausdorfDistance.png}
  \caption{A graphical representation of the Hausdorff Distance, taken from \cite{reinkeCommonLimitationsImage2023,reinkeUnderstandingMetricrelatedPitfalls2023}.}
  \label{fig:HD}
\end{figure}

At this point, none of the recommended distance metrics were found to satisfy the criteria for a feasible cost function capable of introducing an error gradient.
Based on the limitations identified in each approach, the pre-computation of as many values as possible to reduce the algorithmic load during optimization was considered ideal.
In previous studies, 3D distance maps were pre-computed to facilitate medical model-image registration \cite{lavalleeRecoveringPositionOrientation1995,zuffiModelbasedMethodReconstruction1999}.
Consequently, a cost function was devised that utilizes pre-computed distance maps to introduce an error gradient, without the need to spawn multiple kernels during each optimization iteration.



\subsection{Modified Mean Distance Cost Function}
Initially, rather than calculating the average distance across all target points – a process that would necessitate spawning multiple sub-kernels – a distance map encoding the distance to the \emph{nearest point} on the target contour was introduced.

With an arbitrary image point defined as $p_{xy}$, and the target contour defined as $T$, we can express this distance map as a grid, $\displaystyle DM_{xy}(T) = \min_{t\in T}d(p_{xy},t)$, where $d(p_{xy},t)$ is any distance function that you want to use. In our case, we use the $L_{1}$-distance for efficient computation. We use OpenCV's \texttt{distanceTransform()} function for this \cite{bradskiOpenCVLibrary2000}.

With an arbitrary image point defined as $p_{xy}$, and the target contour defined as $T$, this distance map can be expressed as a grid, $\displaystyle DM_{xy}(T) = \min_{t\in T}d(p_{xy},t)$, where $d(p_{xy},t)$ represents any chosen distance function.
In this case, the $L_{1}$-distance was selected for efficient computation, utilizing OpenCV's \texttt{distanceTransform()} function for this purpose \cite{bradskiOpenCVLibrary2000}.

Subsequently, a notion of distance between the projected contour and the target contour can be expressed by calculating the average of the element-wise multiplication between the projection and the pre-calculated distance map (\cref{eq:DMCF}).
This approach offers the significant advantage of requiring only a single kernel for each iteration (iterating once per projection and performing a multiplication and atomic addition in memory) as well as sharing a minimum with the Hamming distance.
This is evident by observing that $DM_{x,y}=0$ for points on the target contour, indicating that if $Proj_{x,y}$ were perfectly aligned with this contour, the summation would result in the addition of zeros.


\begin{equation}
  \label{eq:DMCF}
  J = \dfrac{ \sum_{(x,y) \in \text{Image}} Proj_{x,y}DM_{x,y} }{\sum_{(x,y)\in \text{Image}}Proj_{x,y}}
\end{equation}

Unfortunately, the results of this endeavor did not improve the overall performance of the DIRECT algorithm in finding a global minimum for rTSA implants.
The performance was found to be very similar to the previously poor performance when using the Hamming distance cost function.

\subsection{The Psychology of Shape and Mimicking Human Operators}
Early research in computer vision was closely tied to the psychology and neurology of human perception.
Humans possess a remarkable ability to describe what they see, either through language or mathematical notation.
The task of programmatically replicating this skill in computers continues to present significant challenges.
Although some multi-modal speech/vision models have shown promise in a general sense, they lack a deep technical understanding of the visual content they process.


Historically, the first attempts to mathematically describe shapes, vision, images, and curves were rooted in psychological literature \cite{attneaveInformationalAspectsVisual1954,attneaveQuantitativeStudyShape1956,koenderinkStructureImages1984,koenderinkSurfaceShapeCurvature1992}.
This foundation appears appropriate for enhancing rTSA model-image registration.
The task essentially involves decomposing a contour into its basic shape and elemental components.

In the mid-1950s, psychologist Fred Attneave made significant contributions to the understanding of visual information redundancy and the identification of regions in images and shapes that humans perceive as highly salient \cite{attneaveQuantitativeStudyShape1956,attneaveInformationalAspectsVisual1954}.
He discovered that humans could recognize most images even when the shapes were significantly simplified, retaining only the most relevant features.
Attneave identified regions of high curvature, areas with a relatively high change in the normal vector, as carrying the most information about a shape (\cref{fig:attneave}).
He observed that most other line segments were superfluous for shape recognition.


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.45\textwidth]{~/figures/raster/attneave-blob-points.png}
  \includegraphics[width=0.45\textwidth]{~/figures/raster/attneave-cat-contour.png}
  \caption{Some representative examples of the experiments that Fred Attneave performed to establish the primacy of high curvature as salient in shape recreation and recognition, from \cite{attneaveInformationalAspectsVisual1954}.}
  \label{fig:attneave}
\end{figure}

This understanding resonates with surgeons and engineers experienced in manual registration of rTSA implants.
They report that transitioning an image frame from “good” to “great” hinges on achieving visually precise alignment between the corners and edges of the projected 3D model and the fluoroscopic image.
Their emphasis on the importance of accurately aligning high-curvature regions aligns with Attneave's findings.


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.3\textwidth]{~/figures/raster/TSA_original.png}
  \includegraphics[width=0.3\textwidth]{~/figures/raster/TSA_transparent.png}
  \includegraphics[width=0.3\textwidth]{~/figures/raster/TSA_solid.png}
  \caption[Some different model views of a manually registered humeral and glenoid implant in an rTSA system]{Some different model views of a manually registered humeral and glenoid implant in an rTSA system. Of note, each view gives the user a different type of feature to focus on. The original view allows the user to determine the relative orientation based on shading, the transparent view allows the user to see the underlying fluoroscopic image, and the solid view allows the user to focus on specific regions of error. Each is crucial to performing manual registration.}
  \label{fig:TSA-multiview}
\end{figure}

\subsection{Developing a Cost Function for Aligning High-Curvature Regions}

Informed by these findings, the aim was to develop a cost function that facilitates the alignment of high-curvature regions between the target shape and the projected shape.
The constraints, as outlined in the previous chapter, remained: any new cost functions must reach a global minimum concurrently with the Hamming distance, and computational efficiency is paramount.

Given that there is a finite number of high-curvature regions for any given implant, and that their total count can be limited, the disadvantages associated with many surface distances appeared mitigatable.
This mitigation strategy would involve focusing exclusively on these high-curvature regions rather than every pixel along the surface.
However, this approach introduced the challenge of having to spawn sub-kernels for each iteration.

To circumvent this, an \emph{asymmetric surface distance}, where $d(a,b) \ne d(b,a)$, became necessary.
Such a distance metric would allow for the pre-computation of a distance map based on the target shape.
Since this target does not change with each iteration, and memory usage is manageable due to the small number of points required for distance calculation, this approach seemed promising.
By focusing on pre-computed distances for critical high-curvature points, it was possible to maintain computational efficiency while potentially improving the accuracy of alignment.


\subsubsection{Finding regions of high curvature}
The first step in implementing this cost function involves determining the regions with high curvature in the contour, a task that is not as straightforward as it may appear.
This requires a contour-extraction algorithm, a discrete curvature equation, and a method for automatically selecting regions of high curvature.

OpenCV's \texttt{findContours} function \cite{bradskiOpenCVLibrary2000} is utilized, which provides a pre-specified number of contiguous contour points following an algorithm proposed by Suzuki and Abe \cite{suzukiTopologicalStructuralAnalysis1985}.
For the implementation at hand, 200 contour points are extracted.


For a discrete implementation of curvature, Menger's Algorithm \cite{legerMengerCurvatureRectifiability1999} is implemented.
This method defines the discrete curvature as the reciprocal of the radius of a circle fit through three points along the contour (\cref{eq:menger}).
Typically, a window of size $t$ is defined to increase the proximity of the three points along the curvature, making the calculations more robust to noise.
In this implementation, $t=18$.


\begin{equation}
  \label{eq:menger}
  \begin{split}
  C_{i} &= \dfrac{1}{radius(p_{i-t},p_{i},p_{i+t})}\\
        &\text{where} \\
        radius(x,y,z) &= \dfrac{4 \cdot Area}{|x-y||y-z||z-x|}
  \end{split}
\end{equation}

Given the utilization of neural network segmentation for the contour, the presence of some noise in the contour (\cref{fig:tsa-curv}) is inevitable, leading to noise in the curvature calculations.
Noise was mitigated by applying a 1-D Gaussian convolution to the array of curvature values, employing a 9-wide Gaussian kernel.
Regions of the highest curvature were then represented as peaks along the plot (\cref{fig:tsa-curv}).

To programmatically extract regions with high curvature, two steps were undertaken.
Initially, curvature values were filtered to exclude those where $c_{i} \le \mu_{curvature} + 1.5\sigma_{curvature}$, ensuring the selection of only high curvature points.
Subsequently, inflection points of the first derivative were identified to locate regions where the curvature transitioned from a positive to a negative derivative, indicative of the "peak" of that curvature region.
The points identified by this algorithm correspond precisely to the points where the specific contour exhibits the highest curvature, aligning with the regions that human operators intuitively identified as high curvature areas.


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{~/figures/raster/TSA_curvature.png}
  \caption{A plot demonstrating the values of the Menger Curvature along the contour of an rTSA humeral implant. The regions of high curvature are the peaks of the plot.}
  \label{fig:tsa-curv}
\end{figure}



\subsubsection{Modified asymmetric surface distance}
Upon establishing a set of keypoints representing the regions of the highest curvature, the next step involved determining a pre-computable distance metric for creating a cost function.
The Hausdorff distance was ruled out due to its focus on the maximum distance point rather than incorporating each point's contribution to the overall distance.
The Symmetric distance was also dismissed in favor of seeking an asymmetric function to avoid the necessity of spawning sub-kernels during iteration calls.
Thus, the Mean Surface Distance was selected.
The modified approach eliminated distance calculations from the projection to the target (creating asymmetry) and focused only on distances centered at the selected keypoints.
Distance maps to each keypoint were pre-computed using OpenCV's \texttt{distanceTransform()}, and element-wise multiplication was applied to identify the nearest projected point to each keypoint (\cref{eq:curv-keypoint}).

\begin{equation}
  \label{eq:curv-keypoint}
  \begin{split}
    \displaystyle J &= \dfrac{\sum_{k \in \mathbb{K}}(\min_{p\in Proj}(p \cdot DM_{k}))}{N} \\
      &\text{where}\\
    \mathbb{K} &= \text{Set of all keypoints} \\
    N &= \text{Number of keypoints} \\
    DM_{k} &= \text{Distance map for keypoint $k$} \\
    p &= \text{Single point on projection silhouette}
  \end{split}
\end{equation}

Unfortunately, this approach also resulted in suboptimal performance.
Despite algorithmically identifying salient image features and minimizing the distance of these points to the estimation, the optimization routine failed to accurately match the solution to human-supervised registration.

\subsection{Discussion}
This section delved into the exploration of applying JointTrack Machine Learning to reverse Total Shoulder Arthroplasty implants.
Although the applications did not yield a successful solution for rTSA model-image registration, they contributed to expanding the body of knowledge in the field.

First, all algorithms were rigorously tested on TKA implant registration to ensure no adverse impact on the established performance of JTML.
Given the strengths listed for each algorithm, they might offer stronger and more robust performance than the traditional Hamming distance for TKA implants.
This hypothesis warrants further testing and evaluation, suggesting that the described additions could significantly improve JTML's convergence speed and overall accuracy.

Moreover, although the methods did not succeed in aligning rTSA implants, they demonstrated a comprehensive understanding and a valuable resource for model-image registration endeavors.
The methodical and calculated approach to employing a wide array of mathematical tools to tackle a challenging problem is beneficial for anyone facing a similar technical obstacle.

Lastly, the inability of the methods to accurately perform model-image registration highlighted potential deficiencies in the overall pipeline.
One such deficiency could be attributed to the performance ceiling of the CNN segmentation, though this seems unlikely given the state-of-the-art IOU scores.
Incorporating a surface-based metric into the neural network error functions might yield a more robust segmentation.
Another limitation could be the use of Euler angles in the optimization process, where a more robust rotation parametrization, such as Quaternions, might mitigate the non-commutativity issues.
Additionally, the shape of humeral implants compared to TKA implants, which are more ``cylindrical,'' suggests that minor orientation changes do not significantly alter the projected shape, complicating optimization efforts.

Each identified deficiency represents a promising avenue for future research and development.
The exploration of these potential areas of improvement could lead to significant advancements in model-image registration techniques.
The final section of this chapter will address the potential sensitivity of the projected shape to input orientation, further exploring the nuances of this complex and evolving area of study.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Andrew_Jensen_Dissertation"
%%% End:

\subsection{Introduction}


The application of Joint Track Machine Learning to reverse Total Shoulder Arthroplasty (rTSA) implants has unfolded a complex scenario.
It highlights the intricate relationship between optimization algorithm performance, specific cost functions, and the inherent shape of the 3D models used for registration.
A particular challenge lies in the intrinsic properties of humeral models, which present unique difficulties in model-image registration.
To address these challenges, a thorough understanding of the relationship between a 3D shape and its projective geometry is crucial.
This understanding is expected to shed light on the stark differences in algorithmic performance between total knee arthroplasty (TKA) and rTSA implants.


Understanding shape and its salient features has been a crucial aspect of computer vision since it was intertwined with psychology and neurology \cite{attneaveInformationalAspectsVisual1954,attneaveQuantitativeStudyShape1956}.
Many intuitively appealing ideas about shape, such as the salience of curvature and vanishing points in projections, required mathematical definition to be effectively incorporated into image processing algorithms.
Invariant Shape Descriptors, which remain consistent across rigid transformations or scaling, are particularly significant \cite{zhangReviewShapeRepresentation2004}.
These descriptors encapsulate the essence of a shape, independent of factors like rotation, scaling, or position in an image.
Normalized Fourier Descriptors are among the most notable examples of invariant shape descriptors that have been used for aircraft recognition \cite{wallaceEfficientThreedimensionalAircraft1980,wallaceAnalysisThreedimensionalMovement1980,richardIdentificationThreeDimensionalObjects1974}, aerial photography classification \cite{linClassificationPartial2D1987}, model-image registration \cite{zossoBiplanar2Dto3DRegistration2008}, and even measuring TKA kinematics from single-plane images \cite{banksAccurateMeasurementThreedimensional1996}.
Hu moments \cite{huVisualPatternRecognition1962}, the Hough Transform \cite{ballardGeneralizingHoughTransform1981}, Shape Context \cite{belongieShapeMatchingObject2002}, Curvature scale space \cite{koenderinkSurfaceShapeCurvature1992}, the Angular Radial Transform \cite{leeNewShapeDescription2012}, and multi-scale Shape Descriptors \cite{al-thelayaInShaDeInvariantShape2021} have all been proposed as robust methods for vectorizing a shape into mathematically comparable elements.

The central inquiry of this chapter is whether a robust binary shape descriptor can elucidate the relative underperformance of model-image registration for rTSA implants compared to TKA implants. This question not only addresses a specific technical challenge but also aims to contribute to the broader understanding of shape analysis in medical imaging.

\subsection{Methods}
\subsubsection{Data Collection}
First, we collected one manufacturer-provided model from each of: rTSA humeral implant, rTSA glenosphere implant, TKA femoral implant, and TKA tibial implant for testing shape sensitivity.
\subsubsection{Image Generation}
The binary silhouette of each implant was rendered using an in-house CUDA camera model (CUDA Version 12.1) \cite{nickollsScalableParallelProgramming2008} to a $1024\times 1024$ image plane.
The focal length of the pinhole camera model was 1000mm and each pixel was 0.3mm.
All CUDA programming was performed on an NVIDIA Quadro P2200 GPU.
\subsection{Invariant Angular Radial Transform}
The invariant angular radial transform descriptor (IARTD) was selected due to its sensitivity in the radial direction \cite{leeNewShapeDescription2012}.
This sensitivity allows us to address minor changes along the contour of our projected shape, which is a desirable property for determining the minor changes in shape with respect to input orientation.

The IARTD is a complex moment calculated by summing orthogonal basis components on the unit polar disk.
Each basis function has an order ($n$) and a repetition ($p$).
Intuitively, the order represents concentric ``rings'' in our polar disk, and the repetition is the number of ``pie slices'' in our unit disk along $\theta$.
To perform these calculations, we normalize our image such that $(0,0)$ is at the center and $(\pm1,\pm1)$ are the four corners.

Each angular radial transform (ART) coefficient is a complex double integral (\cref{eq:F_np}) over the image in polar coordinates, $f(\rho,\theta)$ multiplied by the ART basis function, $V_{np}(\rho,\theta)$ (\cref{eq:V_np}).

\begin{equation}
	\label{eq:F_np}
	F_{np} = \int_{0}^{2\pi}\int_{0}^{1}f(\rho,\theta)V_{np}(\rho,\theta)\rho d\rho d\theta
\end{equation}

\begin{equation}
	\label{eq:V_np}
	V_{np}(\rho,\theta) = A_{p}(\theta)R_{n}(\rho)
\end{equation}

Our radial basis function is comprised of a complex exponential, $A_{p}(\theta)$ (\cref{eq:A_p}), which provides rotational invariance, and a trigonometric transform, $R_{p}(\theta)$ (\cref{eq:R_n}) to provide orthogonality.

\begin{equation}
	\label{eq:A_p}
	A_{p}(\theta) = \dfrac{1}{2\pi}e^{jp\theta}
\end{equation}
\begin{equation}
	\label{eq:R_n}
	R_{n}(\rho) =
	\begin{cases}
		1                   & n=0     \\
		2 \cos (\pi n \rho) & n \ne 0
	\end{cases}
\end{equation}

Lastly, in order to correct for differences in the in-plane rotation, we apply a phase-correction to each ART coefficient (\cref{eq:art_phase_correction}, \cref{eq:fnp_phase_correction}).
\begin{equation}
	\label{eq:art_phase_correction}
	\phi'_{np} = \phi_{np} - \phi_{n,1}
\end{equation}

\begin{equation}
	\label{eq:fnp_phase_correction}
	F_{np}' = F_{np}e^{-jp\phi_{n,1}}
\end{equation}

And the, the final feature vector becomes a the polar decomposition of our coefficient at each order and repetition \cref{eq:iartd}.
We exclude values from the first two repetitions because they contain no valuable information.
To construct the full IARTD feature vector, we used values of $n=\{0, \dots, 3 \}$ and $p=\{0, \dots, 8\}$.

\begin{equation}
	\label{eq:iartd}
	IARTD = \{|F'_{np}|, \phi_{np}'\} \text{ where } n \ge 0, p \ge 2
\end{equation}

\subsubsection{Shape Differences and Sensitivity}
The primary goal of this section is to establish a easily interpretable value that captures the overall change from one shape to another.
For clarity in representation, successive rotations were denoted as subscripts, such that $R_{z}R_{x}R_{y} = R_{z,x,y}$. The application of the IARTD equation to an implant at a specific input orientation $R_{z,x,y}$ was represented as $IARTD(R_{z,x,y})$.
Shape differences were calculated using the central difference equation on the IARTD vector produced from two different orientations.
The grid of sampled orientations had extrema of $\pm 30$ with a step size of $5$ for each of the $x$, $y$, and $z$ axes.
The ``differences'' along each axes were computed by applying a positive and negative rotation ($\pm \delta $) of 1 degree.
And so, for every input $x,y,z$ rotation, there will be three shape differences, one for each $\delta_{x}$, $\delta_{y}$ or $\delta_{z}$ (\cref{eq:shape-derivative}).
For notational brevity, we will condense the full equation down to a single $\Delta S(\delta)$, (representing $\Delta Shape$ for a differential rotation $\delta$).

\begin{equation}
	\label{eq:shape-derivative}
	\Delta S(\delta)_{z,x,y} \equiv \dfrac{ \partial IARTD(R_{z,x,y}) }{\partial \delta} \propto IARTD(R_{z,x,y,+\delta}) - IARTD(R_{z,x,y,-\delta})
\end{equation}

Because each element of the IARTD vector is at a different scale, we must standardize each element in order to ensure accurate assessment of global behavior without analysis being dominated by a single value.
We use z-score to do this, which assumes a normal distribution, but allows for some outliers if they are present.


After z-scaling, we took the Euclidean norm of each $S(\delta)_{z,x,y}$ to capture the total amount of change of that shape for a given differential rotation (\cref{eq:euc_norm}).
Our final step takes advantage of two factors: first, that our in-plane rotations are the first in our Euler sequence ($z$-axis), and second, that this type of rotation does not affect the in-plane shape.
And so, for every $x$ and $y$ input rotation, we average all the values where $x$ and $y$ are held constant as $z$ varies (\cref{eq:z_rot_norm}).
This yields our final values, which we will denote $\mathbb{S}$.
$\mathbb{S}_{x,y}$ will have separate plots for each $x$, $y$, and $z$ differential rotation and for each of the four implants.
These plots will be compared with respect to JTML optimization performance and regions of difficulty for optimization.


\begin{equation}
	\label{eq:euc_norm}
	\|S(\delta)_{z,x,y}\|_{2}
\end{equation}

\begin{equation}
	\label{eq:z_rot_norm}
	\mathbb{S}(\delta)_{x,y} = \dfrac{\sum_{z} \| S(\delta)_{z,x,y} \|_{2}}{N}
\end{equation}

\subsection{Results}

The average value of $\mathbb{S}(\delta_{y})$ for the humeral implant was much lower than all other implant types (\cref{fig:hum_sensitivity_plot}) (\cref{tab:ss-vals}).
This rotation represents the final rotation in our Euler rotation sequence (Z-X-Y) and captures the internal/external rotation of the humeral implant.
The average $\delta_{x}$ value for our humeral implant was the largest among all implants (\cref{tab:ss-vals}).
Additionally, the surface plotted by the humeral shape sensitivity for all $\delta_{x,y,z}$ is much smoother than any of the other plots, demonstrating the relative lack of shape difference for a wide range of input orientations.
Many other plots had regions of relative in-sensitivity, like the glenosphere $\delta_{y}$ sensitivity along the $y=0$ axis (\cref{fig:sca_sensitivity_plot}) and the tibial $\delta_{y}$ sensitivity along the $x=0$ axis (\cref{fig:tib_sensitivity_plot}).
The femoral implant had the highest average sensitivity ($\frac{\mathbb{S}(\delta_{x}) +\mathbb{S}(\delta_{y}) +\mathbb{S}(\delta_{z})  }{3}$) among all implant types .


\begin{table}
	\caption{Average projected-shape sensitivity values for each of the implant models.} \label{tab:ss-vals}
	\begin{tabularx}{\textwidth}{|X|X|X|X|}\hline
		{\bf Implant Type} & Average $\mathbb{S}(\delta_{x})$ & Average  $\mathbb{S}(\delta_{y})$ & Average $\mathbb{S}(\delta_{z})$ \\ \hline
		Humeral            & 8.83                             & 4.82                              & 7.08                             \\\hline
		Glenosphere        & 6.37                             & 6.22                              & 4.86                             \\\hline
		Femoral            & 6.88                             & 8.68                              & 4.93                             \\\hline
		Tibial             & 9.0                              & 5.52                              & 3.72                             \\\hline
	\end{tabularx}
\end{table}


\begin{figure}[h!]
	\centering
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Humeral_dx_sensitivity.png}
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Humeral_dy_sensitivity.png}
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Humeral_dz_sensitivity.png}
	\caption{The $\mathbb{S}$ plot for a humeral implant for $\delta$ rotations along the x, y, and z axis, respectively.}
	\label{fig:hum_sensitivity_plot}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Glenosphere_dx_sensitivity.png}
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Glenosphere_dy_sensitivity.png}
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Glenosphere_dz_sensitivity.png}
	\caption{The $\mathbb{S}$ plot for a glenosphere implant for $\delta$ rotations along the x, y, and z axis, respectively.}
	\label{fig:sca_sensitivity_plot}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Femoral_dx_sensitivity.png}
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Femoral_dy_sensitivity.png}
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Femoral_dz_sensitivity.png}
	\caption{The $\mathbb{S}$ plot for a femoral implant for $\delta$ rotations along the x, y, and z axis, respectively.}
	\label{fig:fem_sensitivity_plot}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Tibial_dx_sensitivity.png}
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Tibial_dy_sensitivity.png}
	\includegraphics[width=0.3\linewidth]{~/figures/raster/Tibial_dz_sensitivity.png}
	\caption{The $\mathbb{S}$ plot for a tibial implant for $\delta$ rotations along the x, y, and z axis, respectively.}
	\label{fig:tib_sensitivity_plot}
\end{figure}


\subsection{Discussion}
The results shown align with many of our intuitive expectations about measuring the sensitivity of projected shape with respect to 3D object orientation, as well as aligned with the regions of difficulty for JTML optimization.
The humeral implant demonstrated an overall smooth and low shape sensitivity, especially for $\delta_{y}$ rotations (\cref{tab:ss-vals}).
This axis is the axis along which the humeral implant is the most cylindrical, which means that we would not expect to see a large change in the shape descriptor with minor $\delta_{y}$ rotations.
Additionally, this is the axis which JTML had the most difficulty with.

We see similar intuitive results in the glenosphere implant, which had the lowest average $\mathbb{S}(\delta)$ value among all implant types.
This bulk of the volume of this implant is the articulation surface, which closely resembles a sphere.
Because the projection of a sphere (a circle) is unchanging with respect to the orientation of a sphere, we would expect that the more closely a shape resembles a sphere, then we should expect a lower overall shape sensitivity.

We see that the shape sensitivity of the tibial implant along the $\delta_{y}$ rotation corroborates our intuition about symmetry traps.
Along the line defined by $x=0$, we see a consistently low shape sensitivity.
This internal/external rotation axis is exactly the axis that caused issues with symmetry traps, wherein 2 distinct 3D orientations produce the same projected shape.
In the context of this discussion, we would say that the $\Delta S = 0$ between those two tibial orientations.

Another aspect of Joint Track Machine Learning that this study informs is the current use of Euler angles in our DIRECT-JTA optimization routine.
Rather than independently varying all angles in a body-centered reference frame, which is insuitable for hyperbox creation, we are presently optimizing over a range of ordered rotations projected via the sequence $R_{z}R_{x}R_{y}$.
As evidenced by the humeral implant's struggles aligning the $y$-axis, this ordered sequence with a symmetric final axis can impede convergence.

Beyond the inherent shape sensitivities, such optimization limitations motivate exploring alternatives to Euler angles.
Performing registration optimization directly on the Special Orthogonal group $SO(3)$ poses an intriguing direction.
$SO(3)$ encapsulates all possible 3D rotations in a mathematically convenient structure (A \emph{Lie Group}, which is both a manifold and a group).
By optimizing on this manifold instead of using specific angle parametrizations, issues with gimbal lock and cascade effects can be avoided.
Optimization over Lie groups is an emerging subfield - establishing robust $SO(3)$-based registration cost functions could significantly improve JTML convergence while relying less on descriptor sensitivity along certain axes.

\subsubsection{Code Examples}


\begin{lstlisting}
  // IARTD.cpp
std::vector<float> calculateIARTD(img_desc* img_desc_gpu,
                                  gpu_cost_function::GPUImage* dev_image) {
    /**
     * This is a function to calculate the Invariant Angular Radial Transform
     Descriptor.
     * See: J.-M. Lee and W.-Y. Kim, A New Shape Description Method Using
     Angular Radial Transform, IEICE Trans. Inf. \& Syst., vol. E95.D, no. 6,
     pp. 1628-1635, 2012, doi: 10.1587/transinf.E95.D.1628.
     * The input is a binary image (either a segmentation or a projected image),
     and the output is the vector containing the descriptor variables.
     */
    const int MAX_P =
        8;  // Setting max values for the number of "rings" and "angles"
    const int MAX_N = 3;
    float phase_n_1[MAX_N + 1];  // Creating array for phase correction term
    // (Eqs 15, 16)
    int H = img_desc_gpu->height();
    int W = img_desc_gpu->width();
    std::vector<float> iartd(2 * (MAX_N + 1) * (MAX_P + 1));

    auto idx = [](int n, int p) -> int {
        return (n * MAX_P + p - 1) * 2;
    };  // Lambda for easy indexing
    for (int n = 0; n <= MAX_N; n++) {
        for (int p = 0; p <= MAX_P; p++) {
            std::complex<float> fnp = img_desc_gpu->art_n_p(n, p, dev_image);
            if (p > 1) {
                iartd[idx(n, p)] = abs(fnp) / (float)(H * W);
                iartd[idx(n, p) + 1] = arg(fnp) / (float)(H * W);

            } else if (p == 1) {
                // But, we want to keep values at p=1 for the normalization
                // procedure
                phase_n_1[n] = arg(fnp);
            }
        }
    }
    // Phase Correction using values from p = 1 (Eq 15, 16)
    for (int n = 0; n <= MAX_N; n++) {
        for (int p = 2; p <= MAX_P; p++) {
            std::complex<float> fnp_prime =
                std::complex<float>(iartd[idx(n, p)], iartd[idx(n, p) + 1]) *
                exp(std::complex<float>(0.0, -p * phase_n_1[n]));
            iartd[idx(n, p)] = abs(fnp_prime);
            iartd[idx(n, p) + 1] -= phase_n_1[n];
        }
    }
    return iartd;
'';
\end{lstlisting}

\begin{lstlisting}
  // IARTD.cu
  // These are the associated CUDA Kernels for IARTD Calculations
__global__ void art_np_kernel(int height, int width, int n, int p,
                              unsigned char* image, float* dev_fnp_re,
                              float* dev_fnp_imag, int left_x, int bottom_y) {
    // thread values
    int thread_x = (blockIdx.x * blockDim.x) + threadIdx.x;
    int thread_y = (blockIdx.y * blockDim.y) + threadIdx.y;

    int x = thread_x + left_x;
    int y = thread_y + bottom_y;

    int orig_loc = x + width * y;

    if (x < width && y < height) {
        // Define some vectors that will be used to construct rho in polar
        // coords
        float x_vec = x - width / 2;
        float y_vec = y - height / 2;
        // We normalize rho to have a diameter equal to the width of the
        // image
        //  This prevents the corners from having some of the "basis"
        //  functions, but this is the way that the paper presents it
        float rho = sqrtf(x_vec * x_vec + y_vec * y_vec) / (width / 2);

        // Theta in polar coords based on where we are in the image
        float theta = atan2f(y_vec, x_vec);
        // We Are only looking at a normalized rho of 1
        // This is part of the integration
        if (rho <= 1) {
            // This is the R-cos functon that is used to derive some of the
            // angular invariance (Eq 7)
            float R = (n == 0) ? 1.0 : 2.0 * cosf(3.1415928 * n * rho);
            // This is defining A, which gives rotation invariance (Eq 6)
            thrust::complex<float> A =
                (1 / (2 * 3.1415928)) *
                exp(thrust::complex<float>(0.0, p * theta));
            // This is defining the integration over the whole image, and
            // constructiong the full value of F_np (Eq 4)
            thrust::complex<float> fnp_complex = image[orig_loc] * A * R * rho;
            atomicAdd(&dev_fnp_re[0], fnp_complex.real());
            atomicAdd(&dev_fnp_imag[0], fnp_complex.imag());
        }
    }
  }

std::complex<float> img_desc::art_n_p(int n, int p,
                                      gpu_cost_function::GPUImage* dev_image) {
    // Standard defintion for creating our work groups
    const int threads_per_block = 256;
    int* bounding_box = dev_image->GetBoundingBox();
    int left_x = max(bounding_box[0], 0);
    int bottom_y = max(bounding_box[1], 0);
    int right_x = min(bounding_box[2], width_ - 1);
    int top_y = min(bounding_box[3], height_ - 1);
    int diff_cropped_width = right_x - left_x - 1;
    int diff_cropped_height = top_y - bottom_y + 1;

    dim3 dim_grid_bounding_box =
        dim3(ceil(static_cast<float>(diff_cropped_width) /
                  sqrt(static_cast<float>(threads_per_block))),
             ceil(static_cast<float>(diff_cropped_height) /
                  sqrt(static_cast<float>(threads_per_block))));

    dim3 dim_block = dim3(ceil(sqrt(static_cast<float>(threads_per_block))),
                          ceil(sqrt(static_cast<float>(threads_per_block))));

    // Reset the variables that we are storing
    reset_vars<<<1, 1>>>(dev_Fnp_re, dev_Fnp_imag);
    // Run the kernel
    art_np_kernel<<<dim_grid_bounding_box, dim_block>>>(
        height_, width_, n, p, dev_image->GetDeviceImagePointer(), dev_Fnp_re,
        dev_Fnp_imag, left_x, bottom_y);

    // Copying everything back to host (CPU)
    cudaMemcpy(Fnp_re, dev_Fnp_re, sizeof(float), cudaMemcpyDeviceToHost);
    cudaMemcpy(Fnp_imag, dev_Fnp_imag, sizeof(float), cudaMemcpyDeviceToHost);

    // Returning the value of the complex function that we have calculated.
    std::complex<float> fnp(Fnp_re[0], Fnp_imag[0]);
    return fnp;
};


\end{lstlisting}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Andrew_Jensen_Dissertation"
%%% End:

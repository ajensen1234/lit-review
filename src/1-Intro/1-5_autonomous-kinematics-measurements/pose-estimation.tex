Hand-in-hand with implant detection is the initial pose estimate that very often needs to be input into the optimization routine. Once the contour of the implant was determined, many methods required a human operator to place the implant in the ``capture region'' of their optimizer in order for it to eventually find the correct solution. This takes human supervision to get correct, thus adding another impediment toward getting this technology into the clinic.

To determine an initial estimate, we must rely on those methods that can leverage information present in the camera projection (\Cref{sec:img-form-camera-props}) and the 2D CNN output (\Cref{sec:implant-detection}). The primary method that takes advantage of this information utilizing normalized fourier descriptor shape libraries, and extracting each of the 6 degrees-of-freedom from either the normalized coefficients or matching with the closest entry in the library \cite{wallaceAnalysisThreedimensionalMovement1980,wallaceEfficientThreedimensionalAircraft1980,banksModelBased3D1992,banksAccurateMeasurementThreedimensional1996}. The key feature that makes this method tractable for autonomous measurements is the availability of the implant pixels from the convolutional neural network.

\subsubsection{Generating Normalized Fourier Descriptors}
\label{sec:nfd}
The Fourier Transform is one that takes in a continuous and repeating function and represents it as a sum of sinusoidal signals. Because the implant contour is self intersection, we can view it as a continuous function that has period $2\pi$ radians, as it will loop back onto itself and start over. This allows us to take advantage of the Fast Fourier Transform (FFT) \cite{cochranWhatFastFourier1967}, which operates on a discrete set of points rather than a continuous function. First, the contour of the segmented implant is taken then resampled into 128 equi-spaced points. The choice of $2^n$ points allows the FFT algorithm to perform much more quickly than another choice of points. Each contour point on the image $(x, y)$ is then represented as a single complex point, $x = jy$, such that the 1D FFT algorithm can be used. If $s(n)$ represents the complex sequence of equi-spaced contour points in the implant, and $S(i)$ represents the frequncy-domain representation of those points after the FFT is applied, then we can represent these functions as shown in \cref{eq:fft}.

\begin{equation}
    \begin{aligned}
        S(i) &= \sum_{n = -\frac{N}{2} + 1}^{\frac{N}{2}} s(n)e^{-j(2\pi i n)/N} \\
        &\text{for } -\frac{N}{2} + 1 \le i \le \frac{N}{2} \\
        s(n) &= \frac{1}{N} \sum_{i = \frac{N}{2} + 1}^{\frac{N}{2}} S(i)e^{j(2\pi i n )/N}\\
        &\text{for } -\frac{N}{2} + 1 \le n \le \frac{N}{2}
    \end{aligned}
    \label{eq:fft}
\end{equation}

As discussed in \Cref{sec:image-similarity}, spatial information in images is difficult for computers to understand without explicit calculation. So, we use the properties of the FFT to normalize each of the shapes based on location, rotation, and size in order to accurately compare the segmented mask to a generated library.

\paragraph*{Normalize Position}
By the properties of the FFT, we know that $S(0)$ is the geometric centroid of the contour. Thus, we can set this to zero for all contours to give a consistent reference point that is independent of the location of the input contour. We can save this value as the ``position normalization coefficient'' to determine the $(x,y)$ location of the implant later in the process. And, because of our usage of the 1D FFT, we know that the real portion of this coefficient is the x-value and the imaginary portion is the y-value.

\begin{equation}
    \begin{aligned}
        \text{Position Coefficient} &\leftarrow S(0) \\
        S(0) &= 0
    \end{aligned}
\end{equation}

\paragraph*{Normalize Size}
Because the implant is not self-intersecting, we know that $S(1)$ is the coefficient with the largest size, and it also represent the scale of the shape of the imaplant. So, we can normalize each shape by dividing each coefficient by the overall size of the contour, shown below.

\begin{equation}
    \begin{aligned}
        \text{Size Coefficient} &\leftarrow |S(1)| \\
        S(i) &= \frac{S(i)}{|S(1)|} & \\
        & & \text{for } -\frac{N}{2} + 1 < i < \frac{N}{2}
    \end{aligned}
\end{equation}


\paragraph*{Normalize In-Plane Rotation and Contour Starting Point}

One of the most difficult parts of measuring the similarity between two contours, especially when they are composed of a set of discrete points, is that any distance measurement necessarily takes into account those discrete points in the order that they are presented. To illustrate this example, imagine two squares, each defined by the location of the corners $A_i,B_i,C_i,D_i$. If these two squares are perfectly overlapping, one might imagine that the Euclidean distance between each of the points, $(\sum_{P \in A,B,C,D} (P_1 - P_2)^2)^{\frac{1}{2}}$ would be equal to zero. This would only be true if the starting point of the contour was the same for each square (e.g. Corner $A$ was always the top left corner). If each square had $A$ starting in different locations, then even when the contours are perfectly aligned, the distance metric would be non-zero and uninformative. 

We can use properties of the FFT to normalize the starting position of the contour in each of the segmentations as well as the general orientation of the contour. We can leverage the starting point shift property of the fourier transform (\cref{eq:fft-starting-point}) and the rotation property (\cref{eq:fft-rotation}) in order to normalize both of these factors and ensure that similar shapes have the same orientation and starting point. 

\begin{equation}
    s(n-T) \xleftrightarrow[]{DFT} S(i)e^{-jiT}
    \label{eq:fft-starting-point}
\end{equation}

\begin{equation}
    s(n)e^{j\theta} \xleftrightarrow[]{DFT} S(i)e^{j\theta}
    \label{eq:fft-rotation}
\end{equation}

To normalize the starting point and rotation, we find $k$ such that $S(k)$ is the coefficient of second largest magnitude. We then apply a mixture of the starting point shift and the rotation property of the FFT to orient each contour (\cref{eq:fft-rot-norm}). We also want to find the ``rotation normalization coefficient'', which the the angle through which the contour needs to rotate to reach the normalized orientation. This is done by determining the phase of the normalization equation at $i = 0$, which controls the overall orientation of the contour. If $u$ is the phase of $S(1)$, and $v$ is the phase of $S(k)$, then we can find the normalized orientation.

\begin{equation}
    \begin{aligned}
    \text{Rotation Normalization Coefficient} &\leftarrow \frac{v - ku}{k-1}\\
    S(i)_{norm} &= S(i)e^{j\frac{(i-k)u + (1-i)v}{k-1}} & \\
    & & \text{for } - \frac{N}{2}+1 \le i \le \frac{N}{2}
    \end{aligned}
    \label{eq:fft-rot-norm}
\end{equation}

Once the in-plane rotations have been normalized, the contour has been completely normalized for $x, y,z$ translations and $z$ rotations. And, by storing these values, we are able to utilize them in determining an initial pose estimate. Then, we can use a library made up of known $x,y$ rotations, and compare the segmentation to this library to determine all 6 degrees-of-freedom.

\subsubsection{Shape Library}
A shape library is created using a flat panel projection (\Cref{sec:img-form-camera-props}) of the implant at known $x$ and $y$ rotations, while holding all positions and orientations constant, then applying the normalization protocol described above to determine the normalized coefficients of each library entry. If $s_{x,y}(n)$ is the flat-panel projection of the implant with $x$ and $y$ rotations, then we can generate a library using the following procedure, where $FFT$ is the fast fourier transform (\cref{eq:fft}) and $NFD$ is the process of normalizing the contour and extracting the relevant coefficients (\cref{sec:nfd}).

\begin{equation}
    S^{lib}_{x,y}(i) = NFD(FFT(s_{x,y}(n)))
    \label{eq:lib-generation}
\end{equation}

Once the shape library is generated for a specific implant, we can start to determine the pose estimates for each degree of freedom.

\subsubsection{Generating a Pose Estimate}
First, we compare the Euclidean distance of the normalized segmentation contour to each value of the shape library; the $x$ and $y$ rotations that minimize this function are taken as the $x$ and $y$ rotations of the implant (\cref{eq:library-min}).

\begin{equation}
    (\theta_{x,est},\theta_{y,est}) = \argmin_{x,y}(\sum_{i = -\frac{N}{2} + 1}^{\frac{N}{2}}(S^{seg}(i) - S^{lib}_{x,y}(i))^2)^{\frac{1}{2}}
    \label{eq:library-min}
\end{equation}

Then, we can determine the $z$ rotation estimate by comparing the values of the normalized $\theta$ values that were needed in \cref{eq:fft-rot-norm}. This process is shown in \cref{eq:z-rot-est}.

\begin{equation}
    \begin{aligned}
        \theta_{z,est} &= \theta^{seg} - \theta^{lib}_{x,y}\\
        \text{where } \theta^{seg,lib} &\equiv \text{Rotation Normalized Coefficient}
    \end{aligned}
\label{eq:z-rot-est}
\end{equation}

We can then use the principals of projective geometry (\cref{fig:perspective-projection}) and similar triangles to determine the out-of-plane translation of the implant, given that the library was projected at a known depth. Using similar triangles, we are able to determine that the depth is inversely proportional to the overall magnitude of the projection, captured by the ``Size Coefficient'' (\cref{eq:z-est}). We also make the assumption that we have a weak perspective projection, meaning that the out-of-plane translations are small compared to the focal length of the fluoroscopy imaging setup.

\begin{equation}
    \begin{aligned}
        \frac{M^{seg}}{f} &= \frac{h}{z_{est}}\\
        \frac{M^{lib}}{f} &= \frac{h}{z_{lib}}\\
        & \rightarrow \\
        z_{est}& = \frac{M^{lib}}{M^{seg}}z_{lib} \\
        &\text{where }\\
        M^{seg,lib} &\equiv \text{Size Coefficients} \\
        h &\equiv \text{Implant Size}
    \end{aligned}
    \label{eq:z-est}
\end{equation}

The $x$ and $y$ translations can be determined using the value of the $z$ translation estimate, along with the location of the centroid, saved as the ``Position Coefficient''. This is then refined further to account for the rotation of the implant and the distance of the implant's centroid to its origin. We can express this with a single matrix multiplication multiplied by a scale factor (\cref{eq:x-y-est}).

\begin{equation}
    \begin{pmatrix}
        x_{est} \\ y_{est}
    \end{pmatrix} = \begin{pmatrix}
        Re(S^{seg}(0)) \\ Imag(S^{seg}(0))
    \end{pmatrix} - \begin{pmatrix}
        cos(\theta_z) & -sin(\theta_z) \\ sin(\theta_z) & cos(\theta_z)
    \end{pmatrix}\begin{pmatrix}
        Re(S^{lib}_{x,y}(0)) \\ Imag(S^{lib}_{x,y}(0))
    \end{pmatrix} \times (\frac{z_{est}}{z_{lib}})
    \label{eq:x-y-est}
\end{equation}

Once this step is complete, we have accounted for $x$ and $y$ rotations (\cref{eq:library-min}), $z$ rotations (\cref{eq:z-rot-est}), $x$ and $y$ translations (\cref{eq:x-y-est}), and $z$ translations (\cref{eq:z-est}). This provides a robust initial estimate when the only information available is the implant geometry and the segmentation output from the neural network. Furthermore, this can be done without any human supervision, providing a fully autonomous initialization for any pose refinement strategy, so long as the estimate is within the convergence region.
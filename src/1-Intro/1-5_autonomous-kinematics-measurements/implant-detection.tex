Determining the location of an object in an image is a historically intractable problem. These are one of those tasks that are often relegated to the corner of ``easy for humans, extremely difficult for computers'', especially when there is very little a-priori information available. However, as discussed in \Cref{sec:deep-learning}, deep learning has paved the way for computer vision programs to be able to performs tasks that were once only possible by humans. Two convolutional neural networks were trained to segment that tibial and femoral components from the single plane fluoroscopic images. The network achitecture used was the High-Resolution Net \cite{wangDeepHighResolutionRepresentation2020}, which leverages low-level features with higher resolution parallel processing in order to better determine the spatial characteristics of the image and produce a better output. At the time of writing, this network sets the state-of-the-art standard for performance on the COCO and ImageNet datasets, demonstrating robustness for use in many different arenas.

\begin{center}
    \Large{put some pictures here of the segmentation performance of the neural network}
\end{center}

Many of the historic methods of determining kinematics were limited by the researchers ability to quickly and reliably determine the location in the implant. The contours were either hand-segmented \cite{banksAccurateMeasurementThreedimensional1996, zuffiModelbasedMethodReconstruction1999}, or a normal edge detector was used, which introduces extra tuning parameters for any given study due to variations in image quality.


\subsubsection{Neural Network Robustness}
One of the main problems with neural networks is overfitting. With millions of parameters to tune, it can be extremely easy to ``overfit'' on your training set, leading to the network's inability to perform well on any image that was not directly in the training set. When dealing with fluoroscopic images, this might look like a neural network that can perform extremely well on high-quality, high frame rate, low blur images from a hospital that has a budget to support such a machine, while failing to segment images from a machine more than a decade old. We overcame this challenge through a mixture of additional image augmentations \cite{buslaevAlbumentationsFastFlexible2020} and using a wide range of training data. The neural networks were trained on roughly 8000 images from 7 different human-supervised total knee kinematics studies spanning the last two decades. The image qualities range from extremely clear and high quality to nearly indiscernible without intense human supervision. The goal of this two-pronged approach was to have both artifical and real ``low quality'' images for the network to train on so that any hospital or researcher, regardless of the available equipment, might be able to leverage this technology in their practice. The authors hope that this approach provides equal access to this informative measurement.
One of the biggest limitations in historic forms of image processing and filtering is the need to create and tune the filters that are used for feature extraction. While this gives researchers an exceptional amount of control over the filtering techniques, this is often time consuming and difficult to generalize to new data. Deep learning and neural networks offer algorithms for which feature extraction is automated, and techniques have been introduced that make these algorithms robust to new data.

\input{src/1-Intro/1-2_machine-learning/nn-telos.tex}
\input{src/1-Intro/1-2_machine-learning/neural-network-structure.tex}
\input{src/1-Intro/1-2_machine-learning/training-neural-networks.tex}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../../Andrew_Jensen_Dissertation"
%%% End:

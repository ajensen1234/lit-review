Many of the issues encountered during the ``kinematics translator'' are directly applicable to generating synthetic kinematics data as well.
Fundamentally, the core challenge remains consistent: converting an interpretable latent space into actionable kinematics measurements.
This process necessitates a robust latent space as the source for generating synthetic data, which runs into exactly the same difficulties as trying to build a kinematics translator.
The lack of standardization of kinematics measurements, as well as inconsistently reported post-operative outcomes, means that it would be nearly impossible to train a latent space that is both interpretable (e.g. being able to generate a ``healthy'' or ``pathological'' kinematics sequence) and robust (i.e. $\xi_{\phi} \pm \delta = \xi$).

One of the main benefits of having a tool to easily, accurately, and autonomously measure kinematics data is that the door will be open to creating standard procedures for these measurements.
The next step in adopting this technology clinically involves establishing a universal framework that both clinicians and researchers can utilize when performing a kinematics evaluation.
With the spread of anonymized health datasets, a kinematics dataset containing thousands of patients all performing the same activities, and each having the same post-operative metrics recorded, would pave the way for quantitative assessment and correlation of kinematics data to outcome.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../Andrew_Jensen_Dissertation"
%%% End:
